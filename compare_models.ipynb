{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import tree, ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data_path = './data/Loan_Default.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>year</th>\n",
       "      <th>loan_limit</th>\n",
       "      <th>Gender</th>\n",
       "      <th>approv_in_adv</th>\n",
       "      <th>loan_type</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>Credit_Worthiness</th>\n",
       "      <th>open_credit</th>\n",
       "      <th>business_or_commercial</th>\n",
       "      <th>...</th>\n",
       "      <th>credit_type</th>\n",
       "      <th>Credit_Score</th>\n",
       "      <th>co-applicant_credit_type</th>\n",
       "      <th>age</th>\n",
       "      <th>submission_of_application</th>\n",
       "      <th>LTV</th>\n",
       "      <th>Region</th>\n",
       "      <th>Security_Type</th>\n",
       "      <th>Status</th>\n",
       "      <th>dtir1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24890</td>\n",
       "      <td>2019</td>\n",
       "      <td>cf</td>\n",
       "      <td>Sex Not Available</td>\n",
       "      <td>nopre</td>\n",
       "      <td>type1</td>\n",
       "      <td>p1</td>\n",
       "      <td>l1</td>\n",
       "      <td>nopc</td>\n",
       "      <td>nob/c</td>\n",
       "      <td>...</td>\n",
       "      <td>EXP</td>\n",
       "      <td>758</td>\n",
       "      <td>CIB</td>\n",
       "      <td>25-34</td>\n",
       "      <td>to_inst</td>\n",
       "      <td>98.728814</td>\n",
       "      <td>south</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24891</td>\n",
       "      <td>2019</td>\n",
       "      <td>cf</td>\n",
       "      <td>Male</td>\n",
       "      <td>nopre</td>\n",
       "      <td>type2</td>\n",
       "      <td>p1</td>\n",
       "      <td>l1</td>\n",
       "      <td>nopc</td>\n",
       "      <td>b/c</td>\n",
       "      <td>...</td>\n",
       "      <td>EQUI</td>\n",
       "      <td>552</td>\n",
       "      <td>EXP</td>\n",
       "      <td>55-64</td>\n",
       "      <td>to_inst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24892</td>\n",
       "      <td>2019</td>\n",
       "      <td>cf</td>\n",
       "      <td>Male</td>\n",
       "      <td>pre</td>\n",
       "      <td>type1</td>\n",
       "      <td>p1</td>\n",
       "      <td>l1</td>\n",
       "      <td>nopc</td>\n",
       "      <td>nob/c</td>\n",
       "      <td>...</td>\n",
       "      <td>EXP</td>\n",
       "      <td>834</td>\n",
       "      <td>CIB</td>\n",
       "      <td>35-44</td>\n",
       "      <td>to_inst</td>\n",
       "      <td>80.019685</td>\n",
       "      <td>south</td>\n",
       "      <td>direct</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24893</td>\n",
       "      <td>2019</td>\n",
       "      <td>cf</td>\n",
       "      <td>Male</td>\n",
       "      <td>nopre</td>\n",
       "      <td>type1</td>\n",
       "      <td>p4</td>\n",
       "      <td>l1</td>\n",
       "      <td>nopc</td>\n",
       "      <td>nob/c</td>\n",
       "      <td>...</td>\n",
       "      <td>EXP</td>\n",
       "      <td>587</td>\n",
       "      <td>CIB</td>\n",
       "      <td>45-54</td>\n",
       "      <td>not_inst</td>\n",
       "      <td>69.376900</td>\n",
       "      <td>North</td>\n",
       "      <td>direct</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24894</td>\n",
       "      <td>2019</td>\n",
       "      <td>cf</td>\n",
       "      <td>Joint</td>\n",
       "      <td>pre</td>\n",
       "      <td>type1</td>\n",
       "      <td>p1</td>\n",
       "      <td>l1</td>\n",
       "      <td>nopc</td>\n",
       "      <td>nob/c</td>\n",
       "      <td>...</td>\n",
       "      <td>CRIF</td>\n",
       "      <td>602</td>\n",
       "      <td>EXP</td>\n",
       "      <td>25-34</td>\n",
       "      <td>not_inst</td>\n",
       "      <td>91.886544</td>\n",
       "      <td>North</td>\n",
       "      <td>direct</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  year loan_limit             Gender approv_in_adv loan_type  \\\n",
       "0  24890  2019         cf  Sex Not Available         nopre     type1   \n",
       "1  24891  2019         cf               Male         nopre     type2   \n",
       "2  24892  2019         cf               Male           pre     type1   \n",
       "3  24893  2019         cf               Male         nopre     type1   \n",
       "4  24894  2019         cf              Joint           pre     type1   \n",
       "\n",
       "  loan_purpose Credit_Worthiness open_credit business_or_commercial  ...  \\\n",
       "0           p1                l1        nopc                  nob/c  ...   \n",
       "1           p1                l1        nopc                    b/c  ...   \n",
       "2           p1                l1        nopc                  nob/c  ...   \n",
       "3           p4                l1        nopc                  nob/c  ...   \n",
       "4           p1                l1        nopc                  nob/c  ...   \n",
       "\n",
       "   credit_type  Credit_Score  co-applicant_credit_type    age  \\\n",
       "0          EXP           758                       CIB  25-34   \n",
       "1         EQUI           552                       EXP  55-64   \n",
       "2          EXP           834                       CIB  35-44   \n",
       "3          EXP           587                       CIB  45-54   \n",
       "4         CRIF           602                       EXP  25-34   \n",
       "\n",
       "   submission_of_application        LTV Region Security_Type  Status dtir1  \n",
       "0                    to_inst  98.728814  south        direct       1  45.0  \n",
       "1                    to_inst        NaN  North        direct       1   NaN  \n",
       "2                    to_inst  80.019685  south        direct       0  46.0  \n",
       "3                   not_inst  69.376900  North        direct       0  42.0  \n",
       "4                   not_inst  91.886544  North        direct       0  39.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda_df = pd.read_csv(data_path)\n",
    "eda_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of data: 148670\n",
      "# of features: 34\n",
      "\n",
      "feature name/dtype\n",
      "ID: int64\n",
      "year: int64\n",
      "loan_limit: object\n",
      "Gender: object\n",
      "approv_in_adv: object\n",
      "loan_type: object\n",
      "loan_purpose: object\n",
      "Credit_Worthiness: object\n",
      "open_credit: object\n",
      "business_or_commercial: object\n",
      "loan_amount: int64\n",
      "rate_of_interest: float64\n",
      "Interest_rate_spread: float64\n",
      "Upfront_charges: float64\n",
      "term: float64\n",
      "Neg_ammortization: object\n",
      "interest_only: object\n",
      "lump_sum_payment: object\n",
      "property_value: float64\n",
      "construction_type: object\n",
      "occupancy_type: object\n",
      "Secured_by: object\n",
      "total_units: object\n",
      "income: float64\n",
      "credit_type: object\n",
      "Credit_Score: int64\n",
      "co-applicant_credit_type: object\n",
      "age: object\n",
      "submission_of_application: object\n",
      "LTV: float64\n",
      "Region: object\n",
      "Security_Type: object\n",
      "Status: int64\n",
      "dtir1: float64\n",
      "\n",
      " # of numerical item: 13/# of categorical item: 21\n",
      "\n",
      "statistcal infos\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>year</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>rate_of_interest</th>\n",
       "      <th>Interest_rate_spread</th>\n",
       "      <th>Upfront_charges</th>\n",
       "      <th>term</th>\n",
       "      <th>property_value</th>\n",
       "      <th>income</th>\n",
       "      <th>Credit_Score</th>\n",
       "      <th>LTV</th>\n",
       "      <th>Status</th>\n",
       "      <th>dtir1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>148670.000000</td>\n",
       "      <td>148670.0</td>\n",
       "      <td>1.486700e+05</td>\n",
       "      <td>112231.000000</td>\n",
       "      <td>112031.000000</td>\n",
       "      <td>109028.000000</td>\n",
       "      <td>148629.000000</td>\n",
       "      <td>1.335720e+05</td>\n",
       "      <td>139520.000000</td>\n",
       "      <td>148670.000000</td>\n",
       "      <td>133572.000000</td>\n",
       "      <td>148670.000000</td>\n",
       "      <td>124549.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>99224.500000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>3.311177e+05</td>\n",
       "      <td>4.045476</td>\n",
       "      <td>0.441656</td>\n",
       "      <td>3224.996127</td>\n",
       "      <td>335.136582</td>\n",
       "      <td>4.978935e+05</td>\n",
       "      <td>6957.338876</td>\n",
       "      <td>699.789103</td>\n",
       "      <td>72.746457</td>\n",
       "      <td>0.246445</td>\n",
       "      <td>37.732932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42917.476598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.839093e+05</td>\n",
       "      <td>0.561391</td>\n",
       "      <td>0.513043</td>\n",
       "      <td>3251.121510</td>\n",
       "      <td>58.409084</td>\n",
       "      <td>3.599353e+05</td>\n",
       "      <td>6496.586382</td>\n",
       "      <td>115.875857</td>\n",
       "      <td>39.967603</td>\n",
       "      <td>0.430942</td>\n",
       "      <td>10.545435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>24890.000000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.650000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.638000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>8.000000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.967478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>62057.250000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.965000e+05</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>581.490000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>2.680000e+05</td>\n",
       "      <td>3720.000000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>60.474860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>99224.500000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2.965000e+05</td>\n",
       "      <td>3.990000</td>\n",
       "      <td>0.390400</td>\n",
       "      <td>2596.450000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>4.180000e+05</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>75.135870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>136391.750000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>4.365000e+05</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>0.775400</td>\n",
       "      <td>4812.500000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>6.280000e+05</td>\n",
       "      <td>8520.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>86.184211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>173559.000000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>3.576500e+06</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.357000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.650800e+07</td>\n",
       "      <td>578580.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>7831.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID      year   loan_amount  rate_of_interest  \\\n",
       "count  148670.000000  148670.0  1.486700e+05     112231.000000   \n",
       "mean    99224.500000    2019.0  3.311177e+05          4.045476   \n",
       "std     42917.476598       0.0  1.839093e+05          0.561391   \n",
       "min     24890.000000    2019.0  1.650000e+04          0.000000   \n",
       "25%     62057.250000    2019.0  1.965000e+05          3.625000   \n",
       "50%     99224.500000    2019.0  2.965000e+05          3.990000   \n",
       "75%    136391.750000    2019.0  4.365000e+05          4.375000   \n",
       "max    173559.000000    2019.0  3.576500e+06          8.000000   \n",
       "\n",
       "       Interest_rate_spread  Upfront_charges           term  property_value  \\\n",
       "count         112031.000000    109028.000000  148629.000000    1.335720e+05   \n",
       "mean               0.441656      3224.996127     335.136582    4.978935e+05   \n",
       "std                0.513043      3251.121510      58.409084    3.599353e+05   \n",
       "min               -3.638000         0.000000      96.000000    8.000000e+03   \n",
       "25%                0.076000       581.490000     360.000000    2.680000e+05   \n",
       "50%                0.390400      2596.450000     360.000000    4.180000e+05   \n",
       "75%                0.775400      4812.500000     360.000000    6.280000e+05   \n",
       "max                3.357000     60000.000000     360.000000    1.650800e+07   \n",
       "\n",
       "              income   Credit_Score            LTV         Status  \\\n",
       "count  139520.000000  148670.000000  133572.000000  148670.000000   \n",
       "mean     6957.338876     699.789103      72.746457       0.246445   \n",
       "std      6496.586382     115.875857      39.967603       0.430942   \n",
       "min         0.000000     500.000000       0.967478       0.000000   \n",
       "25%      3720.000000     599.000000      60.474860       0.000000   \n",
       "50%      5760.000000     699.000000      75.135870       0.000000   \n",
       "75%      8520.000000     800.000000      86.184211       0.000000   \n",
       "max    578580.000000     900.000000    7831.250000       1.000000   \n",
       "\n",
       "               dtir1  \n",
       "count  124549.000000  \n",
       "mean       37.732932  \n",
       "std        10.545435  \n",
       "min         5.000000  \n",
       "25%        31.000000  \n",
       "50%        39.000000  \n",
       "75%        45.000000  \n",
       "max        61.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('# of data: {}'.format(eda_df.shape[0]))\n",
    "print('# of features: {}\\n'.format(eda_df.shape[1]))\n",
    "\n",
    "print('feature name/dtype')\n",
    "numerical_count = 0\n",
    "categorical_count = 0\n",
    "\n",
    "for feature_name, feature_type in zip(eda_df.columns, eda_df.dtypes):\n",
    "  if np.issubdtype(feature_type, np.number):\n",
    "    numerical_count += 1\n",
    "  else:\n",
    "    categorical_count += 1\n",
    "  print('{}: {}'.format(feature_name, feature_type))\n",
    "\n",
    "print('\\n # of numerical item: {}/# of categorical item: {}'.format(numerical_count, categorical_count))\n",
    "\n",
    "print('\\nstatistcal infos')\n",
    "eda_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status\n",
      "0    112031\n",
      "1     36639\n",
      "Name: count, dtype: int64\n",
      "Majority Class Label: 0 with 112031 instances\n",
      "Minority Class Label: 1 with 36639 instances\n"
     ]
    }
   ],
   "source": [
    "label_df = eda_df['Status']\n",
    "eda_df = eda_df.drop(columns=['ID', 'year', 'Status'])\n",
    "status_counts = label_df.value_counts()\n",
    "print(status_counts)\n",
    "\n",
    "class_counts = label_df.value_counts()\n",
    "\n",
    "#majority, minority 클래스 분류 --> 추후 언더샘플, 오버샘플링을 위해\n",
    "majority_class_label = class_counts.idxmax()\n",
    "minority_class_label = class_counts.idxmin()\n",
    "\n",
    "majority_class_count = class_counts.max()\n",
    "minority_class_count = class_counts.min()\n",
    "print(f\"Majority Class Label: {majority_class_label} with {majority_class_count} instances\")\n",
    "print(f\"Minority Class Label: {minority_class_label} with {minority_class_count} instances\")\n",
    "\n",
    "#불균형 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value_list = ['mean', 'mode', 'median'] #remove 로 하면 데이터가 많이 없어짐...\n",
    "scaling_list = ['min-max', 'standardization']\n",
    "#model_list = ['LogisticRegression', 'DecisionTree', 'RandomForest', 'GBDT', 'XGBoost']\n",
    "imbalance_dataset_list = ['original', 'weight balance', 'undersample', 'oversample']\n",
    "hparams_dict = dict(\n",
    "    LogisticRegression={'lr':[1e-5, 1e-4, 5e-4, 1e-3],\n",
    "                        'epochs':[100]},\n",
    "    DecisionTree={'max_depth':[3, 4, 5],\n",
    "                  'min_sample_leaf':[3, 4]},\n",
    "    RandomForest={'max_depth':[3, 4, 5],\n",
    "                  'n_estimators':[100, 150]},\n",
    "    GBDT={'max_depth':[3, 4, 5],\n",
    "                  'n_estimators':[100, 150]}\n",
    "    \n",
    ")\n",
    "num_class = 2\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 자동화\n",
    "def preprocess(missing_value, scaling, imbalance, test_data_ratio=0.2, random_state=42, verbose=False):\n",
    "    if verbose: print(f'Preprocess with {missing_value}, {scaling}, {imbalance}.')\n",
    "    eda_df = pd.read_csv(data_path)\n",
    "    label_df = eda_df['Status'] #label\n",
    "    eda_df = eda_df.drop(columns=['ID', 'year', 'Status']) #필요없는 컬럼 제거\n",
    "    \n",
    "    #=============================================================================================\n",
    "    #클리닝\n",
    "    duplicates = eda_df.duplicated()\n",
    "    eda_df = eda_df[~duplicates]\n",
    "    label_df = label_df[~duplicates]\n",
    "\n",
    "    if missing_value == 'remove':\n",
    "        non_missing = ~eda_df.isnull().any(axis=1)\n",
    "        eda_df = eda_df[non_missing]\n",
    "        label_df = label_df[non_missing]\n",
    "\n",
    "    else:\n",
    "        for feature_name in eda_df.columns:\n",
    "            \n",
    "            \n",
    "            for feature_name in eda_df.columns:\n",
    "                if eda_df[feature_name].dtype in ['int32', 'int64', 'float32', 'float64']:\n",
    "                    if eda_df[feature_name].isnull().sum() > 0:\n",
    "                        #mean, mode, median 으로 치환\n",
    "                        match missing_value:\n",
    "                            case 'mean':\n",
    "                                fill_value = eda_df[feature_name].mean()\n",
    "                            case 'mode':\n",
    "                                fill_value = eda_df[feature_name].mode()[0]\n",
    "                            case 'median':\n",
    "                                fill_value = eda_df[feature_name].median()\n",
    "                            case _:\n",
    "                                raise NotImplementedError\n",
    "                        eda_df.fillna({feature_name: fill_value}, inplace=True) #future warning\n",
    "                else:\n",
    "                    if eda_df[feature_name].isnull().sum() > 0:\n",
    "                        mode_value = eda_df[feature_name].mode()[0]\n",
    "                        eda_df.fillna({feature_name: mode_value}, inplace=True)\n",
    "    \n",
    "    train_data, test_data, train_label, test_label = train_test_split(eda_df, label_df, test_size=test_data_ratio, random_state=random_state)\n",
    "\n",
    "    #=============================================================================================\n",
    "    #데이터 전처리\n",
    "    train_numerical_features = train_data.select_dtypes(include=[np.number])\n",
    "    train_numerical_array = train_numerical_features.values\n",
    "    test_numerical_features = test_data.select_dtypes(include=[np.number])\n",
    "    test_numerical_array = test_numerical_features.values\n",
    "\n",
    "    if scaling == 'standardization':\n",
    "        train_feature_mean = np.mean(train_numerical_array, axis=0)\n",
    "        train_feature_std = np.std(train_numerical_array, axis=0)\n",
    "\n",
    "        train_feature_std = np.where(train_feature_std == 0, 1e-5, train_feature_std)\n",
    "\n",
    "        train_scaled_data = (train_numerical_array - train_feature_mean) / train_feature_std\n",
    "        test_scaled_data = (test_numerical_array - train_feature_mean) / train_feature_std\n",
    "\n",
    "    elif scaling == 'min-max':\n",
    "        train_data_min = np.min(train_numerical_array, axis=0)\n",
    "        train_data_max = np.max(train_numerical_array, axis=0)\n",
    "\n",
    "        train_data_max = np.where(train_data_max == train_data_min, train_data_min + 1e-5, train_data_max)\n",
    "\n",
    "        train_scaled_data = (train_numerical_array - train_data_min) / (train_data_max - train_data_min)\n",
    "        test_scaled_data = (test_numerical_array - train_data_min) / (train_data_max - train_data_min)\n",
    "\n",
    "    train_categorical_features = train_data.select_dtypes(include=[object])\n",
    "    test_categorical_features = test_data.select_dtypes(include=[object])\n",
    "\n",
    "    train_one_hot_encoded_list = []\n",
    "    test_one_hot_encoded_list = []\n",
    "\n",
    "    train_encoded_feature_count_list = []\n",
    "\n",
    "    #원 핫 인코딩\n",
    "    for feature_name in train_categorical_features.columns:\n",
    "        unique_values = np.unique(train_categorical_features[feature_name])\n",
    "        train_encoded_feature_count_list.append(len(unique_values)+1)\n",
    "\n",
    "        train_encoded_array = np.zeros((train_categorical_features.shape[0], len(unique_values) + 1))\n",
    "        for index, value in enumerate(train_categorical_features[feature_name]):\n",
    "            train_encoded_array[index, np.where(unique_values == value)[0]] = 1\n",
    "        train_one_hot_encoded_list.append(train_encoded_array)\n",
    "\n",
    "        test_encoded_array = np.zeros((test_categorical_features.shape[0], len(unique_values) + 1))\n",
    "        for index, value in enumerate(test_categorical_features[feature_name]):\n",
    "            if value in unique_values:\n",
    "                test_encoded_array[index, np.where(unique_values == value)[0]] = 1\n",
    "            else:\n",
    "                test_encoded_array[index, -1] = 1\n",
    "        test_one_hot_encoded_list.append(test_encoded_array)\n",
    "\n",
    "    train_encoded_array = np.hstack(train_one_hot_encoded_list)\n",
    "    test_encoded_array = np.hstack(test_one_hot_encoded_list)\n",
    "\n",
    "    train_processed_array = np.hstack((train_scaled_data, train_encoded_array))\n",
    "    train_label_array = train_label.to_numpy()\n",
    "\n",
    "    test_processed_array = np.hstack((test_scaled_data, test_encoded_array))\n",
    "    test_label_array = test_label.to_numpy()\n",
    "\n",
    "    #=============================================================================================\n",
    "    # 샘플링\n",
    "    if imbalance == 'undersample' or imbalance == 'oversample':\n",
    "        unique, counts = np.unique(train_label_array, return_counts=True)\n",
    "        class_counts = dict(zip(unique, counts))\n",
    "        minority_class = min(class_counts, key=class_counts.get)\n",
    "        majority_class = max(class_counts, key=class_counts.get)\n",
    "\n",
    "        # minor major index 찾기\n",
    "        minority_indices = np.where(train_label_array == minority_class)[0]\n",
    "        majority_indices = np.where(train_label_array == majority_class)[0]\n",
    "\n",
    "        if imbalance == 'undersample':\n",
    "            if verbose: print(\"undersampling\")\n",
    "            # 언더: majority를 minority 에 맞추어 선택\n",
    "            num_minority = len(minority_indices)\n",
    "            random_majority_indices = np.random.choice(majority_indices, num_minority, replace=False)\n",
    "            selected_indices = np.concatenate([minority_indices, random_majority_indices])\n",
    "        \n",
    "        elif imbalance == 'oversample':\n",
    "            if verbose: print('oversampling')\n",
    "            # 오버: minority를 majority에 맞추어 복사\n",
    "            num_majority = len(majority_indices)\n",
    "            num_minority = len(minority_indices)\n",
    "            repeat_count = (num_majority // num_minority) + 1\n",
    "            oversampled_minority_indices = np.tile(minority_indices, repeat_count)[:num_majority]\n",
    "            selected_indices = np.concatenate([oversampled_minority_indices, majority_indices])\n",
    "        np.random.shuffle(selected_indices)\n",
    "\n",
    "        train_processed_array = train_processed_array[selected_indices]\n",
    "        train_label_array = train_label_array[selected_indices]\n",
    "\n",
    "    return train_processed_array, train_label_array, test_processed_array, test_label_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처리 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess with mean, standardization, original.\n",
      "{0: 89537, 1: 29399}\n"
     ]
    }
   ],
   "source": [
    "train_processed_array, train_label_array, test_processed_array, test_label_array = preprocess('mean', \"standardization\", 'original', test_data_ratio=0.2, random_state=42)\n",
    "unique, counts = np.unique(train_label_array, return_counts=True)\n",
    "class_counts = dict(zip(unique, counts))\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess with mean, standardization, oversample.\n",
      "oversampling\n",
      "{0: 89537, 1: 89537}\n"
     ]
    }
   ],
   "source": [
    "train_processed_array, train_label_array, test_processed_array, test_label_array = preprocess('mean', \"standardization\", 'oversample', test_data_ratio=0.2, random_state=42)\n",
    "unique, counts = np.unique(train_label_array, return_counts=True)\n",
    "class_counts = dict(zip(unique, counts))\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess with mean, standardization, undersample.\n",
      "undersampling\n",
      "{0: 29399, 1: 29399}\n"
     ]
    }
   ],
   "source": [
    "train_processed_array, train_label_array, test_processed_array, test_label_array = preprocess('mean', \"standardization\", 'undersample', test_data_ratio=0.2, random_state=42)\n",
    "unique, counts = np.unique(train_label_array, return_counts=True)\n",
    "class_counts = dict(zip(unique, counts))\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchLogisticRegression(nn.Module):\n",
    "  def __init__(self, data, num_class):\n",
    "    super(TorchLogisticRegression, self).__init__()\n",
    "    self.logistic_regressor = nn.Linear(data.shape[1], num_class)\n",
    "\n",
    "  def forward(self, data):\n",
    "    logit = self.logistic_regressor(data)\n",
    "\n",
    "    return logit\n",
    "\n",
    "  def get_params(self):\n",
    "    torch_weight, torch_bias = self.logistic_regressor.weight.detach().cpu().numpy(), self.logistic_regressor.bias.detach().cpu().numpy()\n",
    "\n",
    "    return torch_weight, torch_bias\n",
    "  \n",
    "def train_torch_model(data, label, model, criterion, optimizer, epochs, device):\n",
    "  model.train()\n",
    "\n",
    "  data, label = torch.tensor(data, dtype=torch.float32).to(device), torch.tensor(label, dtype=torch.long).to(device)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    result = model(data)\n",
    "\n",
    "    loss = criterion(result, label)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "def test_torch_model(data, label, model, device):\n",
    "  model.eval()\n",
    "\n",
    "  data = torch.tensor(data, dtype=torch.float32).to(device)\n",
    "  with torch.no_grad():\n",
    "    result = model(data)\n",
    "    _, result = torch.max(result, 1)\n",
    "\n",
    "    result = result.cpu()\n",
    "    accuracy = accuracy_score(label, result)\n",
    "    recall = recall_score(label, result)\n",
    "    precision = precision_score(label, result)\n",
    "    f1_measure = f1_score(label, result)\n",
    "\n",
    "    print('acc: {}'.format(accuracy))\n",
    "    print('recall: {}'.format(recall))\n",
    "    print('precision: {}'.format(precision))\n",
    "    print('f1 score: {}'.format(f1_measure))\n",
    "\n",
    "def get_inverse_class_frequency_weights(label):\n",
    "    num_data = label.shape[0]\n",
    "\n",
    "    num_negative_data = np.where(label == 0)[0].shape[0]\n",
    "    num_positive_data = np.where(label == 1)[0].shape[0]\n",
    "\n",
    "    negative_weight = num_data / (num_negative_data * 2)\n",
    "    positive_weight = num_data / (num_positive_data * 2)\n",
    "\n",
    "    class_weights = torch.tensor([negative_weight, positive_weight], dtype=torch.float32)\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean, min-max, original, 1e-05, 100\n",
      "==========\n",
      "acc: 0.6170713661128674\n",
      "recall: 0.5270718232044199\n",
      "precision: 0.3239938869077942\n",
      "f1 score: 0.40130402776317176\n",
      "\n",
      "mean, min-max, original, 0.0001, 100\n",
      "==========\n",
      "acc: 0.7560368601600861\n",
      "recall: 0.0015193370165745856\n",
      "precision: 0.3055555555555556\n",
      "f1 score: 0.0030236393622869707\n",
      "\n",
      "mean, min-max, original, 0.0005, 100\n",
      "==========\n",
      "acc: 0.7565749646868904\n",
      "recall: 0.00027624309392265195\n",
      "precision: 1.0\n",
      "f1 score: 0.0005523336095001381\n",
      "\n",
      "mean, min-max, original, 0.001, 100\n",
      "==========\n",
      "acc: 0.7565413331539652\n",
      "recall: 0.00013812154696132598\n",
      "precision: 1.0\n",
      "f1 score: 0.00027620494406849883\n",
      "\n",
      "mean, min-max, weight balance, 1e-05, 100\n",
      "==========\n",
      "acc: 0.3045671621712518\n",
      "recall: 0.8794198895027624\n",
      "precision: 0.2432752559987773\n",
      "f1 score: 0.38112055548904583\n",
      "\n",
      "mean, min-max, weight balance, 0.0001, 100\n",
      "==========\n",
      "acc: 0.5520279814353938\n",
      "recall: 0.6320441988950276\n",
      "precision: 0.3004201680672269\n",
      "f1 score: 0.4072623709505162\n",
      "\n",
      "mean, min-max, weight balance, 0.0005, 100\n",
      "==========\n",
      "acc: 0.6581690993475483\n",
      "recall: 0.6024861878453038\n",
      "precision: 0.3744848901098901\n",
      "f1 score: 0.4618805590851334\n",
      "\n",
      "mean, min-max, weight balance, 0.001, 100\n",
      "==========\n",
      "acc: 0.6926414205959508\n",
      "recall: 0.648756906077348\n",
      "precision: 0.415921367218631\n",
      "f1 score: 0.5068796201370528\n",
      "\n",
      "mean, min-max, undersample, 1e-05, 100\n",
      "==========\n",
      "acc: 0.4474675455707271\n",
      "recall: 0.8718232044198895\n",
      "precision: 0.2893687250722046\n",
      "f1 score: 0.4345162289608646\n",
      "\n",
      "mean, min-max, undersample, 0.0001, 100\n",
      "==========\n",
      "acc: 0.6026770700208516\n",
      "recall: 0.5052486187845304\n",
      "precision: 0.3076534903280067\n",
      "f1 score: 0.38243596445373756\n",
      "\n",
      "mean, min-max, undersample, 0.0005, 100\n",
      "==========\n",
      "acc: 0.6899845294948543\n",
      "recall: 0.6505524861878453\n",
      "precision: 0.41323039129671874\n",
      "f1 score: 0.5054190363772937\n",
      "\n",
      "mean, min-max, undersample, 0.001, 100\n",
      "==========\n",
      "acc: 0.72919889688572\n",
      "recall: 0.6301104972375691\n",
      "precision: 0.45913848631239934\n",
      "f1 score: 0.5312063344201211\n",
      "\n",
      "mean, min-max, oversample, 1e-05, 100\n",
      "==========\n",
      "acc: 0.3274029730275106\n",
      "recall: 0.7656077348066298\n",
      "precision: 0.232459635143636\n",
      "f1 score: 0.35663503297410326\n",
      "\n",
      "mean, min-max, oversample, 0.0001, 100\n",
      "==========\n",
      "acc: 0.5131499293737809\n",
      "recall: 0.4910220994475138\n",
      "precision: 0.24780426599749059\n",
      "f1 score: 0.3293801538033911\n",
      "\n",
      "mean, min-max, oversample, 0.0005, 100\n",
      "==========\n",
      "acc: 0.6969798883433107\n",
      "recall: 0.6211325966850829\n",
      "precision: 0.41778149386845037\n",
      "f1 score: 0.49955565429904464\n",
      "\n",
      "mean, min-max, oversample, 0.001, 100\n",
      "==========\n",
      "acc: 0.7082464518732764\n",
      "recall: 0.6519337016574586\n",
      "precision: 0.4340229885057471\n",
      "f1 score: 0.5211150979850953\n",
      "\n",
      "mean, standardization, original, 1e-05, 100\n",
      "==========\n",
      "acc: 0.7033362480661869\n",
      "recall: 0.062292817679558014\n",
      "precision: 0.18163511880789368\n",
      "f1 score: 0.0927697212794405\n",
      "\n",
      "mean, standardization, original, 0.0001, 100\n",
      "==========\n",
      "acc: 0.7566422277527409\n",
      "recall: 0.0005524861878453039\n",
      "precision: 1.0\n",
      "f1 score: 0.0011043622308117063\n",
      "\n",
      "mean, standardization, original, 0.0005, 100\n",
      "==========\n",
      "acc: 0.7564740700881146\n",
      "recall: 0.0\n",
      "precision: 0.0\n",
      "f1 score: 0.0\n",
      "\n",
      "mean, standardization, original, 0.001, 100\n",
      "==========\n",
      "acc: 0.7568103854173673\n",
      "recall: 0.0012430939226519336\n",
      "precision: 1.0\n",
      "f1 score: 0.0024831011173955028\n",
      "\n",
      "mean, standardization, weight balance, 1e-05, 100\n",
      "==========\n",
      "acc: 0.5411313647676061\n",
      "recall: 0.22900552486187845\n",
      "precision: 0.1705761316872428\n",
      "f1 score: 0.1955188679245283\n",
      "\n",
      "mean, standardization, weight balance, 0.0001, 100\n",
      "==========\n",
      "acc: 0.5560301338535011\n",
      "recall: 0.5505524861878454\n",
      "precision: 0.28608339912438097\n",
      "f1 score: 0.3765172625513626\n",
      "\n",
      "mean, standardization, weight balance, 0.0005, 100\n",
      "==========\n",
      "acc: 0.6708481872603753\n",
      "recall: 0.6519337016574586\n",
      "precision: 0.3937599065654459\n",
      "f1 score: 0.4909762313413429\n",
      "\n",
      "mean, standardization, weight balance, 0.001, 100\n",
      "==========\n",
      "acc: 0.7585592251294814\n",
      "recall: 0.6611878453038674\n",
      "precision: 0.5032061389677284\n",
      "f1 score: 0.5714797349728407\n",
      "\n",
      "mean, standardization, undersample, 1e-05, 100\n",
      "==========\n",
      "acc: 0.2584246989977803\n",
      "recall: 0.9401933701657459\n",
      "precision: 0.23948072051787223\n",
      "f1 score: 0.38172947510094213\n",
      "\n",
      "mean, standardization, undersample, 0.0001, 100\n",
      "==========\n",
      "acc: 0.5686419587004776\n",
      "recall: 0.5812154696132596\n",
      "precision: 0.300528495929153\n",
      "f1 score: 0.39619621504566427\n",
      "\n",
      "mean, standardization, undersample, 0.0005, 100\n",
      "==========\n",
      "acc: 0.6759265487320912\n",
      "recall: 0.6581491712707183\n",
      "precision: 0.39954720778131814\n",
      "f1 score: 0.49723468642387564\n",
      "\n",
      "mean, standardization, undersample, 0.001, 100\n",
      "==========\n",
      "acc: 0.7489742382457792\n",
      "recall: 0.6486187845303868\n",
      "precision: 0.48835274542429286\n",
      "f1 score: 0.5571903179876602\n",
      "\n",
      "mean, standardization, oversample, 1e-05, 100\n",
      "==========\n",
      "acc: 0.4321988296226542\n",
      "recall: 0.4205801104972376\n",
      "precision: 0.1935422360643234\n",
      "f1 score: 0.2650938057719932\n",
      "\n",
      "mean, standardization, oversample, 0.0001, 100\n",
      "==========\n",
      "acc: 0.5504809309208314\n",
      "recall: 0.5596685082872929\n",
      "precision: 0.2847505270555165\n",
      "f1 score: 0.3774569166278528\n",
      "\n",
      "mean, standardization, oversample, 0.0005, 100\n",
      "==========\n",
      "acc: 0.675657496468689\n",
      "recall: 0.6164364640883978\n",
      "precision: 0.393909973521624\n",
      "f1 score: 0.4806677436725902\n",
      "\n",
      "mean, standardization, oversample, 0.001, 100\n",
      "==========\n",
      "acc: 0.7092217663281092\n",
      "recall: 0.662292817679558\n",
      "precision: 0.4360676609676246\n",
      "f1 score: 0.5258828690502303\n",
      "\n",
      "mode, min-max, original, 1e-05, 100\n",
      "==========\n",
      "acc: 0.6512410035649425\n",
      "recall: 0.22914364640883977\n",
      "precision: 0.2572890818858561\n",
      "f1 score: 0.2424021040327294\n",
      "\n",
      "mode, min-max, original, 0.0001, 100\n",
      "==========\n",
      "acc: 0.7561041232259367\n",
      "recall: 0.0027624309392265192\n",
      "precision: 0.38461538461538464\n",
      "f1 score: 0.005485463521667581\n",
      "\n",
      "mode, min-max, original, 0.0005, 100\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CHOI\\Documents\\MLDL_study\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.7565077016210399\n",
      "recall: 0.0\n",
      "precision: 0.0\n",
      "f1 score: 0.0\n",
      "\n",
      "mode, min-max, original, 0.001, 100\n",
      "==========\n",
      "acc: 0.7566085962198157\n",
      "recall: 0.0004143646408839779\n",
      "precision: 1.0\n",
      "f1 score: 0.0008283860278889963\n",
      "\n",
      "mode, min-max, weight balance, 1e-05, 100\n",
      "==========\n",
      "acc: 0.5615120737203202\n",
      "recall: 0.292817679558011\n",
      "precision: 0.21119744969117354\n",
      "f1 score: 0.24539877300613497\n",
      "\n",
      "mode, min-max, weight balance, 0.0001, 100\n",
      "==========\n",
      "acc: 0.7013856191565212\n",
      "recall: 0.20207182320441988\n",
      "precision: 0.3204819277108434\n",
      "f1 score: 0.24786107581533248\n",
      "\n",
      "mode, min-max, weight balance, 0.0005, 100\n",
      "==========\n",
      "acc: 0.6211744131297504\n",
      "recall: 0.6476519337016574\n",
      "precision: 0.34987315326070734\n",
      "f1 score: 0.45431644220521267\n",
      "\n",
      "mode, min-max, weight balance, 0.001, 100\n",
      "==========\n",
      "acc: 0.7060940337660591\n",
      "recall: 0.6596685082872928\n",
      "precision: 0.43217808343136366\n",
      "f1 score: 0.5222240446121044\n",
      "\n",
      "mode, min-max, undersample, 1e-05, 100\n",
      "==========\n",
      "acc: 0.2702629985874756\n",
      "recall: 0.9716850828729282\n",
      "precision: 0.24659983174425126\n",
      "f1 score: 0.3933683739655558\n",
      "\n",
      "mode, min-max, undersample, 0.0001, 100\n",
      "==========\n",
      "acc: 0.5885854577251631\n",
      "recall: 0.5831491712707182\n",
      "precision: 0.3142070402619632\n",
      "f1 score: 0.40837645693282393\n",
      "\n",
      "mode, min-max, undersample, 0.0005, 100\n",
      "==========\n",
      "acc: 0.6704782403981974\n",
      "recall: 0.6140883977900552\n",
      "precision: 0.38829694323144104\n",
      "f1 score: 0.47576243980738364\n",
      "\n",
      "mode, min-max, undersample, 0.001, 100\n",
      "==========\n",
      "acc: 0.7316876303221901\n",
      "recall: 0.6556629834254144\n",
      "precision: 0.4639366692728694\n",
      "f1 score: 0.5433836996336996\n",
      "\n",
      "mode, min-max, oversample, 1e-05, 100\n",
      "==========\n",
      "acc: 0.533160691464317\n",
      "recall: 0.4415745856353591\n",
      "precision: 0.24526275412351362\n",
      "f1 score: 0.31536374845869297\n",
      "\n",
      "mode, min-max, oversample, 0.0001, 100\n",
      "==========\n",
      "acc: 0.5368265285531715\n",
      "recall: 0.6020718232044199\n",
      "precision: 0.2858360655737705\n",
      "f1 score: 0.387638950644731\n",
      "\n",
      "mode, min-max, oversample, 0.0005, 100\n",
      "==========\n",
      "acc: 0.6653662473935562\n",
      "recall: 0.6138121546961326\n",
      "precision: 0.38316951198482496\n",
      "f1 score: 0.4718122942987578\n",
      "\n",
      "mode, min-max, oversample, 0.001, 100\n",
      "==========\n",
      "acc: 0.7374722539853367\n",
      "recall: 0.6412983425414365\n",
      "precision: 0.47127486804709706\n",
      "f1 score: 0.543295108822841\n",
      "\n",
      "mode, standardization, original, 1e-05, 100\n",
      "==========\n",
      "acc: 0.7557005448308334\n",
      "recall: 0.0004143646408839779\n",
      "precision: 0.1\n",
      "f1 score: 0.0008253094910591472\n",
      "\n",
      "mode, standardization, original, 0.0001, 100\n",
      "==========\n",
      "acc: 0.694894733301944\n",
      "recall: 0.3223756906077348\n",
      "precision: 0.35907692307692307\n",
      "f1 score: 0.33973799126637555\n",
      "\n",
      "mode, standardization, original, 0.0005, 100\n",
      "==========\n",
      "acc: 0.7568776484832178\n",
      "recall: 0.0015193370165745856\n",
      "precision: 1.0\n",
      "f1 score: 0.0030340642669976557\n",
      "\n",
      "mode, standardization, original, 0.001, 100\n",
      "==========\n",
      "acc: 0.7601399071769691\n",
      "recall: 0.014917127071823204\n",
      "precision: 1.0\n",
      "f1 score: 0.02939575394665215\n",
      "\n",
      "mode, standardization, weight balance, 1e-05, 100\n",
      "==========\n",
      "acc: 0.39422882895002354\n",
      "recall: 0.8096685082872929\n",
      "precision: 0.2605796586059744\n",
      "f1 score: 0.39426957223567394\n",
      "\n",
      "mode, standardization, weight balance, 0.0001, 100\n",
      "==========\n",
      "acc: 0.39315261989641487\n",
      "recall: 0.3665745856353591\n",
      "precision: 0.16472194637537238\n",
      "f1 score: 0.22730387118876327\n",
      "\n",
      "mode, standardization, weight balance, 0.0005, 100\n",
      "==========\n",
      "acc: 0.6947265756373175\n",
      "recall: 0.7196132596685083\n",
      "precision: 0.4250632291751652\n",
      "f1 score: 0.5344411960814485\n",
      "\n",
      "mode, standardization, weight balance, 0.001, 100\n",
      "==========\n",
      "acc: 0.8112934687563059\n",
      "recall: 0.8058011049723757\n",
      "precision: 0.5811335790417372\n",
      "f1 score: 0.675270559638868\n",
      "\n",
      "mode, standardization, undersample, 1e-05, 100\n",
      "==========\n",
      "acc: 0.5758391067464855\n",
      "recall: 0.6852209944751381\n",
      "precision: 0.3243755721197855\n",
      "f1 score: 0.4403124167924026\n",
      "\n",
      "mode, standardization, undersample, 0.0001, 100\n",
      "==========\n",
      "acc: 0.6379229165265353\n",
      "recall: 0.6379834254143646\n",
      "precision: 0.3618771544970229\n",
      "f1 score: 0.46180763847230555\n",
      "\n",
      "mode, standardization, undersample, 0.0005, 100\n",
      "==========\n",
      "acc: 0.7971345933947669\n",
      "recall: 0.7747237569060773\n",
      "precision: 0.5603396603396603\n",
      "f1 score: 0.6503188405797101\n",
      "\n",
      "mode, standardization, undersample, 0.001, 100\n",
      "==========\n",
      "acc: 0.8476491558485236\n",
      "recall: 0.8176795580110497\n",
      "precision: 0.6484118291347207\n",
      "f1 score: 0.7232742822235797\n",
      "\n",
      "mode, standardization, oversample, 1e-05, 100\n",
      "==========\n",
      "acc: 0.5654469630725768\n",
      "recall: 0.755939226519337\n",
      "precision: 0.32916340891321344\n",
      "f1 score: 0.4586248795407885\n",
      "\n",
      "mode, standardization, oversample, 0.0001, 100\n",
      "==========\n",
      "acc: 0.5213560234075469\n",
      "recall: 0.6383977900552487\n",
      "precision: 0.2846760285784676\n",
      "f1 score: 0.39376384392571134\n",
      "\n",
      "mode, standardization, oversample, 0.0005, 100\n",
      "==========\n",
      "acc: 0.826595816237304\n",
      "recall: 0.8651933701657458\n",
      "precision: 0.5997702029873612\n",
      "f1 score: 0.7084370052024429\n",
      "\n",
      "mode, standardization, oversample, 0.001, 100\n",
      "==========\n",
      "acc: 0.8664155512208247\n",
      "recall: 0.849585635359116\n",
      "precision: 0.6808722603497896\n",
      "f1 score: 0.7559297038220474\n",
      "\n",
      "median, min-max, original, 1e-05, 100\n",
      "==========\n",
      "acc: 0.23949014596085288\n",
      "recall: 0.9715469613259669\n",
      "precision: 0.23891851499609387\n",
      "f1 score: 0.38352280472179057\n",
      "\n",
      "median, min-max, original, 0.0001, 100\n",
      "==========\n",
      "acc: 0.7454765588215511\n",
      "recall: 0.01781767955801105\n",
      "precision: 0.22013651877133106\n",
      "f1 score: 0.03296703296703297\n",
      "\n",
      "median, min-max, original, 0.0005, 100\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CHOI\\Documents\\MLDL_study\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.7565077016210399\n",
      "recall: 0.0\n",
      "precision: 0.0\n",
      "f1 score: 0.0\n",
      "\n",
      "median, min-max, original, 0.001, 100\n",
      "==========\n",
      "acc: 0.7613842738952041\n",
      "recall: 0.02016574585635359\n",
      "precision: 0.9931972789115646\n",
      "f1 score: 0.039528902125355356\n",
      "\n",
      "median, min-max, weight balance, 1e-05, 100\n",
      "==========\n",
      "acc: 0.5106948274702361\n",
      "recall: 0.6567679558011049\n",
      "precision: 0.28271597597954695\n",
      "f1 score: 0.39527827424248724\n",
      "\n",
      "median, min-max, weight balance, 0.0001, 100\n",
      "==========\n",
      "acc: 0.5631936503665838\n",
      "recall: 0.5582872928176795\n",
      "precision: 0.29222093695777906\n",
      "f1 score: 0.3836370539104024\n",
      "\n",
      "median, min-max, weight balance, 0.0005, 100\n",
      "==========\n",
      "acc: 0.6480460079370418\n",
      "recall: 0.6131215469613259\n",
      "precision: 0.36676856977608857\n",
      "f1 score: 0.4589774078478002\n",
      "\n",
      "median, min-max, weight balance, 0.001, 100\n",
      "==========\n",
      "acc: 0.7248604291383601\n",
      "recall: 0.6366022099447514\n",
      "precision: 0.4536863864553598\n",
      "f1 score: 0.5298005632507615\n",
      "\n",
      "median, min-max, undersample, 1e-05, 100\n",
      "==========\n",
      "acc: 0.6688975583507096\n",
      "recall: 0.10732044198895027\n",
      "precision: 0.18682375571050733\n",
      "f1 score: 0.1363277480480744\n",
      "\n",
      "median, min-max, undersample, 0.0001, 100\n",
      "==========\n",
      "acc: 0.2635030604694962\n",
      "recall: 0.9316298342541437\n",
      "precision: 0.23961774841024547\n",
      "f1 score: 0.38119189578682644\n",
      "\n",
      "median, min-max, undersample, 0.0005, 100\n",
      "==========\n",
      "acc: 0.6634492500168158\n",
      "recall: 0.5802486187845304\n",
      "precision: 0.37613036082012713\n",
      "f1 score: 0.45640719213428216\n",
      "\n",
      "median, min-max, undersample, 0.001, 100\n",
      "==========\n",
      "acc: 0.7385484630389453\n",
      "recall: 0.662292817679558\n",
      "precision: 0.4736270248913473\n",
      "f1 score: 0.5522920985947938\n",
      "\n",
      "median, min-max, oversample, 1e-05, 100\n",
      "==========\n",
      "acc: 0.5669603820542141\n",
      "recall: 0.5128453038674033\n",
      "precision: 0.28425968458122797\n",
      "f1 score: 0.36577677076150134\n",
      "\n",
      "median, min-max, oversample, 0.0001, 100\n",
      "==========\n",
      "acc: 0.4842604425909733\n",
      "recall: 0.456353591160221\n",
      "precision: 0.22471604434469156\n",
      "f1 score: 0.30114387276124505\n",
      "\n",
      "median, min-max, oversample, 0.0005, 100\n",
      "==========\n",
      "acc: 0.6833254859756508\n",
      "recall: 0.5556629834254143\n",
      "precision: 0.39356290354138135\n",
      "f1 score: 0.4607719619745734\n",
      "\n",
      "median, min-max, oversample, 0.001, 100\n",
      "==========\n",
      "acc: 0.7073384004842941\n",
      "recall: 0.6541436464088398\n",
      "precision: 0.4331443204682641\n",
      "f1 score: 0.5211841091669418\n",
      "\n",
      "median, standardization, original, 1e-05, 100\n",
      "==========\n",
      "acc: 0.26521826864868503\n",
      "recall: 0.9790055248618784\n",
      "precision: 0.2462479155086159\n",
      "f1 score: 0.3935154341550078\n",
      "\n",
      "median, standardization, original, 0.0001, 100\n",
      "==========\n",
      "acc: 0.7350171520817919\n",
      "recall: 0.017403314917127072\n",
      "precision: 0.1414141414141414\n",
      "f1 score: 0.030992497847743206\n",
      "\n",
      "median, standardization, original, 0.0005, 100\n",
      "==========\n",
      "acc: 0.7566758592856663\n",
      "recall: 0.0009668508287292818\n",
      "precision: 0.7777777777777778\n",
      "f1 score: 0.001931300869085391\n",
      "\n",
      "median, standardization, original, 0.001, 100\n",
      "==========\n",
      "acc: 0.7575502791417232\n",
      "recall: 0.005110497237569061\n",
      "precision: 0.8604651162790697\n",
      "f1 score: 0.01016064808458053\n",
      "\n",
      "median, standardization, weight balance, 1e-05, 100\n",
      "==========\n",
      "acc: 0.48903612026636173\n",
      "recall: 0.5914364640883978\n",
      "precision: 0.2592480474662469\n",
      "f1 score: 0.36048322599654836\n",
      "\n",
      "median, standardization, weight balance, 0.0001, 100\n",
      "==========\n",
      "acc: 0.5665231721261855\n",
      "recall: 0.7031767955801105\n",
      "precision: 0.32158423346598447\n",
      "f1 score: 0.4413332755407221\n",
      "\n",
      "median, standardization, weight balance, 0.0005, 100\n",
      "==========\n",
      "acc: 0.6251429340149324\n",
      "recall: 0.6125690607734806\n",
      "precision: 0.34713525360050096\n",
      "f1 score: 0.4431454836131095\n",
      "\n",
      "median, standardization, weight balance, 0.001, 100\n",
      "==========\n",
      "acc: 0.7224053272348153\n",
      "recall: 0.711878453038674\n",
      "precision: 0.4552199258081611\n",
      "f1 score: 0.5553280896455124\n",
      "\n",
      "median, standardization, undersample, 1e-05, 100\n",
      "==========\n",
      "acc: 0.6738077621577991\n",
      "recall: 0.15883977900552487\n",
      "precision: 0.24164740491699938\n",
      "f1 score: 0.19168264022001832\n",
      "\n",
      "median, standardization, undersample, 0.0001, 100\n",
      "==========\n",
      "acc: 0.45812874150803795\n",
      "recall: 0.6638121546961326\n",
      "precision: 0.2600086561350357\n",
      "f1 score: 0.37365883999378013\n",
      "\n",
      "median, standardization, undersample, 0.0005, 100\n",
      "==========\n",
      "acc: 0.6254792493441851\n",
      "recall: 0.6258287292817679\n",
      "precision: 0.3496681586664609\n",
      "f1 score: 0.44865828299831667\n",
      "\n",
      "median, standardization, undersample, 0.001, 100\n",
      "==========\n",
      "acc: 0.7284590031613641\n",
      "recall: 0.6849447513812155\n",
      "precision: 0.46121651785714285\n",
      "f1 score: 0.5512449977767897\n",
      "\n",
      "median, standardization, oversample, 1e-05, 100\n",
      "==========\n",
      "acc: 0.4075132844555055\n",
      "recall: 0.700828729281768\n",
      "precision: 0.24721071863580998\n",
      "f1 score: 0.36549612821898075\n",
      "\n",
      "median, standardization, oversample, 0.0001, 100\n",
      "==========\n",
      "acc: 0.7015537768211475\n",
      "recall: 0.13204419889502764\n",
      "precision: 0.26959954878736603\n",
      "f1 score: 0.1772668273688114\n",
      "\n",
      "median, standardization, oversample, 0.0005, 100\n",
      "==========\n",
      "acc: 0.6550413667854981\n",
      "recall: 0.6650552486187845\n",
      "precision: 0.3807227010358188\n",
      "f1 score: 0.48423593302157186\n",
      "\n",
      "median, standardization, oversample, 0.001, 100\n",
      "==========\n",
      "acc: 0.729568843747898\n",
      "recall: 0.7037292817679558\n",
      "precision: 0.463561095441725\n",
      "f1 score: 0.5589380725138501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR_hparams = hparams_dict.get('LogisticRegression')\n",
    "LR_lr_list = LR_hparams.get('lr')\n",
    "LR_epochs_list = LR_hparams.get('epochs')\n",
    "\n",
    "for missing_value in missing_value_list:\n",
    "  for scaling in scaling_list:\n",
    "    for imbalance in imbalance_dataset_list:\n",
    "      #데이터 불러오기\n",
    "      train_processed_array, train_label_array, test_processed_array, test_label_array = preprocess(missing_value, scaling, imbalance, test_data_ratio=0.2, random_state=42, verbose=False)\n",
    "\n",
    "      #logistic regression\n",
    "      for lr in LR_lr_list:\n",
    "        for epochs in LR_epochs_list:\n",
    "          \n",
    "          logistic_regressor = TorchLogisticRegression(train_processed_array, num_class).to(device)\n",
    "          model_optimizer = torch.optim.Adam(logistic_regressor.parameters(), lr=lr)\n",
    "          \n",
    "          #weight balance 처리\n",
    "          class_weights = get_inverse_class_frequency_weights(train_label_array).to(device) if imbalance == 'weight balance' else None\n",
    "          criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "          train_torch_model(train_processed_array, train_label_array, logistic_regressor, criterion, model_optimizer, epochs, device)\n",
    "\n",
    "          #print(f'Testing Logistic Regression with\\nMissing Value: {missing_value}\\nScaling: {scaling}\\nImbalance: {imbalance}\\nLearning Rate: {lr}\\nEpochs: {epochs}')\n",
    "          print(f'{missing_value}, {scaling}, {imbalance}, {lr}, {epochs}')\n",
    "          print(\"=\"*10)\n",
    "          test_torch_model(test_processed_array, test_label_array, logistic_regressor, device)\n",
    "          print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최고 F1 Score:\n",
    "\n",
    "모델: median, standardization, weight balance, 0.001, 100\n",
    "F1 Score: 0.5553280896455124\n",
    "Accuracy: 0.7224053272348153\n",
    "Recall: 0.711878453038674\n",
    "Precision: 0.4552199258081611\n",
    "\n",
    "두 번째로 좋은 F1 Score:\n",
    "\n",
    "모델: median, min-max, undersample, 0.001, 100\n",
    "F1 Score: 0.5522920985947938\n",
    "기타 지표:\n",
    "Accuracy: 0.7385484630389453\n",
    "Recall: 0.662292817679558\n",
    "Precision: 0.4736270248913473\n",
    "\n",
    "\n",
    "F1 Score는 precision과 recall 간의 균형을 잘 나타내는 지표이므로, F1 Score가 가장 높은 모델인 'median, standardization, weight balance, 0.001, 100'이 가장 우수한 성능을 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnDecisionTreeClassifier:\n",
    "  def __init__(self, max_depth, min_sample_leaf, random_state):\n",
    "    self.max_depth = max_depth\n",
    "    self.min_sample_leaf = min_sample_leaf\n",
    "    self.random_state = random_state\n",
    "\n",
    "    self.classifier = tree.DecisionTreeClassifier(\n",
    "        max_depth=self.max_depth,\n",
    "        min_samples_leaf=self.min_sample_leaf,\n",
    "        random_state=self.random_state\n",
    "    )\n",
    "\n",
    "  def __call__(self, data):\n",
    "    return self.classifier.predict(data)\n",
    "\n",
    "  def train_model(self, train_data, train_label):\n",
    "      self.classifier.fit(train_data, train_label)\n",
    "\n",
    "  def test_model(self, test_data, test_label):\n",
    "\n",
    "    pred = self.classifier.predict(test_data)\n",
    "    accuracy = accuracy_score(test_label, pred)\n",
    "    precision = precision_score(test_label, pred)\n",
    "    recall = recall_score(test_label, pred)\n",
    "    f1_measure = f1_score(test_label, pred)\n",
    "\n",
    "    print('acc: {}/precision: {}/recall: {}/f1-measure: {}'.format(accuracy, precision, recall, f1_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean, min-max, original, 3, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, original, 3, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, original, 4, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, original, 4, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, original, 5, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, original, 5, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, weight balance, 3, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, weight balance, 3, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, weight balance, 4, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, weight balance, 4, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, weight balance, 5, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, weight balance, 5, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, undersample, 3, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, undersample, 3, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, undersample, 4, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, undersample, 4, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, undersample, 5, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, undersample, 5, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, oversample, 3, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, oversample, 3, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, oversample, 4, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, oversample, 4, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, oversample, 5, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, min-max, oversample, 5, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, original, 3, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, original, 3, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, original, 4, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, original, 4, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, original, 5, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, original, 5, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, weight balance, 3, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, weight balance, 3, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, weight balance, 4, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, weight balance, 4, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, weight balance, 5, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, weight balance, 5, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, undersample, 3, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, undersample, 3, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, undersample, 4, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, undersample, 4, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, undersample, 5, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, undersample, 5, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, oversample, 3, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, oversample, 3, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, oversample, 4, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, oversample, 4, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, oversample, 5, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mean, standardization, oversample, 5, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mode, min-max, original, 3, 3\n",
      "==========\n",
      "acc: 0.9997982108024484/precision: 0.9993097736057427/recall: 0.9998618784530386/f1-measure: 0.9995857497928748\n",
      "\n",
      "mode, min-max, original, 3, 4\n",
      "==========\n",
      "acc: 0.9997982108024484/precision: 0.9993097736057427/recall: 0.9998618784530386/f1-measure: 0.9995857497928748\n",
      "\n",
      "mode, min-max, original, 4, 3\n",
      "==========\n",
      "acc: 0.9998318423353737/precision: 0.9993098688750862/recall: 1.0/f1-measure: 0.9996548153261995\n",
      "\n",
      "mode, min-max, original, 4, 4\n",
      "==========\n",
      "acc: 0.9998318423353737/precision: 0.9993098688750862/recall: 1.0/f1-measure: 0.9996548153261995\n",
      "\n",
      "mode, min-max, original, 5, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mode, min-max, original, 5, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mode, min-max, weight balance, 3, 3\n",
      "==========\n",
      "acc: 0.9997982108024484/precision: 0.9993097736057427/recall: 0.9998618784530386/f1-measure: 0.9995857497928748\n",
      "\n",
      "mode, min-max, weight balance, 3, 4\n",
      "==========\n",
      "acc: 0.9997982108024484/precision: 0.9993097736057427/recall: 0.9998618784530386/f1-measure: 0.9995857497928748\n",
      "\n",
      "mode, min-max, weight balance, 4, 3\n",
      "==========\n",
      "acc: 0.9998318423353737/precision: 0.9993098688750862/recall: 1.0/f1-measure: 0.9996548153261995\n",
      "\n",
      "mode, min-max, weight balance, 4, 4\n",
      "==========\n",
      "acc: 0.9998318423353737/precision: 0.9993098688750862/recall: 1.0/f1-measure: 0.9996548153261995\n",
      "\n",
      "mode, min-max, weight balance, 5, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mode, min-max, weight balance, 5, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mode, min-max, undersample, 3, 3\n",
      "==========\n",
      "acc: 0.9997982108024484/precision: 0.9993097736057427/recall: 0.9998618784530386/f1-measure: 0.9995857497928748\n",
      "\n",
      "mode, min-max, undersample, 3, 4\n",
      "==========\n",
      "acc: 0.9997982108024484/precision: 0.9993097736057427/recall: 0.9998618784530386/f1-measure: 0.9995857497928748\n",
      "\n",
      "mode, min-max, undersample, 4, 3\n",
      "==========\n",
      "acc: 0.9998318423353737/precision: 0.9993098688750862/recall: 1.0/f1-measure: 0.9996548153261995\n",
      "\n",
      "mode, min-max, undersample, 4, 4\n",
      "==========\n",
      "acc: 0.9998318423353737/precision: 0.9993098688750862/recall: 1.0/f1-measure: 0.9996548153261995\n",
      "\n",
      "mode, min-max, undersample, 5, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mode, min-max, undersample, 5, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mode, min-max, oversample, 3, 3\n",
      "==========\n",
      "acc: 0.9997982108024484/precision: 0.9993097736057427/recall: 0.9998618784530386/f1-measure: 0.9995857497928748\n",
      "\n",
      "mode, min-max, oversample, 3, 4\n",
      "==========\n",
      "acc: 0.9997982108024484/precision: 0.9993097736057427/recall: 0.9998618784530386/f1-measure: 0.9995857497928748\n",
      "\n",
      "mode, min-max, oversample, 4, 3\n",
      "==========\n",
      "acc: 0.9998318423353737/precision: 0.9993098688750862/recall: 1.0/f1-measure: 0.9996548153261995\n",
      "\n",
      "mode, min-max, oversample, 4, 4\n",
      "==========\n",
      "acc: 0.9998318423353737/precision: 0.9993098688750862/recall: 1.0/f1-measure: 0.9996548153261995\n",
      "\n",
      "mode, min-max, oversample, 5, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mode, min-max, oversample, 5, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mode, standardization, original, 3, 3\n",
      "==========\n",
      "acc: 0.9997982108024484/precision: 0.9993097736057427/recall: 0.9998618784530386/f1-measure: 0.9995857497928748\n",
      "\n",
      "mode, standardization, original, 3, 4\n",
      "==========\n",
      "acc: 0.9997982108024484/precision: 0.9993097736057427/recall: 0.9998618784530386/f1-measure: 0.9995857497928748\n",
      "\n",
      "mode, standardization, original, 4, 3\n",
      "==========\n",
      "acc: 0.9998318423353737/precision: 0.9993098688750862/recall: 1.0/f1-measure: 0.9996548153261995\n",
      "\n",
      "mode, standardization, original, 4, 4\n",
      "==========\n",
      "acc: 0.9998318423353737/precision: 0.9993098688750862/recall: 1.0/f1-measure: 0.9996548153261995\n",
      "\n",
      "mode, standardization, original, 5, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mode, standardization, original, 5, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mode, standardization, weight balance, 3, 3\n",
      "==========\n",
      "acc: 0.9997982108024484/precision: 0.9993097736057427/recall: 0.9998618784530386/f1-measure: 0.9995857497928748\n",
      "\n",
      "mode, standardization, weight balance, 3, 4\n",
      "==========\n",
      "acc: 0.9997982108024484/precision: 0.9993097736057427/recall: 0.9998618784530386/f1-measure: 0.9995857497928748\n",
      "\n",
      "mode, standardization, weight balance, 4, 3\n",
      "==========\n",
      "acc: 0.9998318423353737/precision: 0.9993098688750862/recall: 1.0/f1-measure: 0.9996548153261995\n",
      "\n",
      "mode, standardization, weight balance, 4, 4\n",
      "==========\n",
      "acc: 0.9998318423353737/precision: 0.9993098688750862/recall: 1.0/f1-measure: 0.9996548153261995\n",
      "\n",
      "mode, standardization, weight balance, 5, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mode, standardization, weight balance, 5, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mode, standardization, undersample, 3, 3\n",
      "==========\n",
      "acc: 0.9997982108024484/precision: 0.9993097736057427/recall: 0.9998618784530386/f1-measure: 0.9995857497928748\n",
      "\n",
      "mode, standardization, undersample, 3, 4\n",
      "==========\n",
      "acc: 0.9997982108024484/precision: 0.9993097736057427/recall: 0.9998618784530386/f1-measure: 0.9995857497928748\n",
      "\n",
      "mode, standardization, undersample, 4, 3\n",
      "==========\n",
      "acc: 0.9998318423353737/precision: 0.9993098688750862/recall: 1.0/f1-measure: 0.9996548153261995\n",
      "\n",
      "mode, standardization, undersample, 4, 4\n",
      "==========\n",
      "acc: 0.9998318423353737/precision: 0.9993098688750862/recall: 1.0/f1-measure: 0.9996548153261995\n",
      "\n",
      "mode, standardization, undersample, 5, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mode, standardization, undersample, 5, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mode, standardization, oversample, 3, 3\n",
      "==========\n",
      "acc: 0.9997982108024484/precision: 0.9993097736057427/recall: 0.9998618784530386/f1-measure: 0.9995857497928748\n",
      "\n",
      "mode, standardization, oversample, 3, 4\n",
      "==========\n",
      "acc: 0.9997982108024484/precision: 0.9993097736057427/recall: 0.9998618784530386/f1-measure: 0.9995857497928748\n",
      "\n",
      "mode, standardization, oversample, 4, 3\n",
      "==========\n",
      "acc: 0.9998318423353737/precision: 0.9993098688750862/recall: 1.0/f1-measure: 0.9996548153261995\n",
      "\n",
      "mode, standardization, oversample, 4, 4\n",
      "==========\n",
      "acc: 0.9998318423353737/precision: 0.9993098688750862/recall: 1.0/f1-measure: 0.9996548153261995\n",
      "\n",
      "mode, standardization, oversample, 5, 3\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "mode, standardization, oversample, 5, 4\n",
      "==========\n",
      "acc: 1.0/precision: 1.0/recall: 1.0/f1-measure: 1.0\n",
      "\n",
      "median, min-max, original, 3, 3\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, min-max, original, 3, 4\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, min-max, original, 4, 3\n",
      "==========\n",
      "acc: 0.9999663684670748/precision: 0.9998618975279657/recall: 1.0/f1-measure: 0.9999309439955805\n",
      "\n",
      "median, min-max, original, 4, 4\n",
      "==========\n",
      "acc: 0.9999663684670748/precision: 0.9998618975279657/recall: 1.0/f1-measure: 0.9999309439955805\n",
      "\n",
      "median, min-max, original, 5, 3\n",
      "==========\n",
      "acc: 0.9999663684670748/precision: 0.9998618975279657/recall: 1.0/f1-measure: 0.9999309439955805\n",
      "\n",
      "median, min-max, original, 5, 4\n",
      "==========\n",
      "acc: 0.9999663684670748/precision: 0.9998618975279657/recall: 1.0/f1-measure: 0.9999309439955805\n",
      "\n",
      "median, min-max, weight balance, 3, 3\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, min-max, weight balance, 3, 4\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, min-max, weight balance, 4, 3\n",
      "==========\n",
      "acc: 0.9999663684670748/precision: 0.9998618975279657/recall: 1.0/f1-measure: 0.9999309439955805\n",
      "\n",
      "median, min-max, weight balance, 4, 4\n",
      "==========\n",
      "acc: 0.9999663684670748/precision: 0.9998618975279657/recall: 1.0/f1-measure: 0.9999309439955805\n",
      "\n",
      "median, min-max, weight balance, 5, 3\n",
      "==========\n",
      "acc: 0.9999663684670748/precision: 0.9998618975279657/recall: 1.0/f1-measure: 0.9999309439955805\n",
      "\n",
      "median, min-max, weight balance, 5, 4\n",
      "==========\n",
      "acc: 0.9999663684670748/precision: 0.9998618975279657/recall: 1.0/f1-measure: 0.9999309439955805\n",
      "\n",
      "median, min-max, undersample, 3, 3\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, min-max, undersample, 3, 4\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, min-max, undersample, 4, 3\n",
      "==========\n",
      "acc: 0.9998654738682989/precision: 0.9998618402873722/recall: 0.999585635359116/f1-measure: 0.9997237187456831\n",
      "\n",
      "median, min-max, undersample, 4, 4\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9998618593728416/recall: 0.9997237569060774/f1-measure: 0.9997928033703986\n",
      "\n",
      "median, min-max, undersample, 5, 3\n",
      "==========\n",
      "acc: 0.9998654738682989/precision: 0.9998618402873722/recall: 0.999585635359116/f1-measure: 0.9997237187456831\n",
      "\n",
      "median, min-max, undersample, 5, 4\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9998618593728416/recall: 0.9997237569060774/f1-measure: 0.9997928033703986\n",
      "\n",
      "median, min-max, oversample, 3, 3\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, min-max, oversample, 3, 4\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, min-max, oversample, 4, 3\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, min-max, oversample, 4, 4\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, min-max, oversample, 5, 3\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, min-max, oversample, 5, 4\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, standardization, original, 3, 3\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, standardization, original, 3, 4\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, standardization, original, 4, 3\n",
      "==========\n",
      "acc: 0.9999663684670748/precision: 0.9998618975279657/recall: 1.0/f1-measure: 0.9999309439955805\n",
      "\n",
      "median, standardization, original, 4, 4\n",
      "==========\n",
      "acc: 0.9999663684670748/precision: 0.9998618975279657/recall: 1.0/f1-measure: 0.9999309439955805\n",
      "\n",
      "median, standardization, original, 5, 3\n",
      "==========\n",
      "acc: 0.9999663684670748/precision: 0.9998618975279657/recall: 1.0/f1-measure: 0.9999309439955805\n",
      "\n",
      "median, standardization, original, 5, 4\n",
      "==========\n",
      "acc: 0.9999663684670748/precision: 0.9998618975279657/recall: 1.0/f1-measure: 0.9999309439955805\n",
      "\n",
      "median, standardization, weight balance, 3, 3\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, standardization, weight balance, 3, 4\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, standardization, weight balance, 4, 3\n",
      "==========\n",
      "acc: 0.9999663684670748/precision: 0.9998618975279657/recall: 1.0/f1-measure: 0.9999309439955805\n",
      "\n",
      "median, standardization, weight balance, 4, 4\n",
      "==========\n",
      "acc: 0.9999663684670748/precision: 0.9998618975279657/recall: 1.0/f1-measure: 0.9999309439955805\n",
      "\n",
      "median, standardization, weight balance, 5, 3\n",
      "==========\n",
      "acc: 0.9999663684670748/precision: 0.9998618975279657/recall: 1.0/f1-measure: 0.9999309439955805\n",
      "\n",
      "median, standardization, weight balance, 5, 4\n",
      "==========\n",
      "acc: 0.9999663684670748/precision: 0.9998618975279657/recall: 1.0/f1-measure: 0.9999309439955805\n",
      "\n",
      "median, standardization, undersample, 3, 3\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, standardization, undersample, 3, 4\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, standardization, undersample, 4, 3\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, standardization, undersample, 4, 4\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, standardization, undersample, 5, 3\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, standardization, undersample, 5, 4\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, standardization, oversample, 3, 3\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, standardization, oversample, 3, 4\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, standardization, oversample, 4, 3\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, standardization, oversample, 4, 4\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, standardization, oversample, 5, 3\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "median, standardization, oversample, 5, 4\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT_hparams = hparams_dict.get('DecisionTree')\n",
    "DT_max_depth_list = DT_hparams.get('max_depth')\n",
    "DT_min_sample_leaf_list = DT_hparams.get('min_sample_leaf')\n",
    "\n",
    "for missing_value in missing_value_list:\n",
    "  for scaling in scaling_list:\n",
    "    for imbalance in imbalance_dataset_list:\n",
    "      #데이터 불러오기\n",
    "      train_processed_array, train_label_array, test_processed_array, test_label_array = preprocess(missing_value, scaling, imbalance, test_data_ratio=0.2, random_state=42, verbose=False)\n",
    "\n",
    "      #Decision Tree\n",
    "      for max_depth in DT_max_depth_list:\n",
    "        for min_sample_leaf in DT_min_sample_leaf_list:\n",
    "          \n",
    "            sklearn_dt_classifier = SklearnDecisionTreeClassifier(max_depth, min_sample_leaf, random_state)\n",
    "            sklearn_dt_classifier.train_model(train_processed_array, train_label_array)\n",
    "\n",
    "            print(f'{missing_value}, {scaling}, {imbalance}, {max_depth}, {min_sample_leaf}')\n",
    "            print(\"=\"*10)\n",
    "            sklearn_dt_classifier.test_model(test_processed_array, test_label_array)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대부분의 케이스가 모두 1.0 이라는 값이 나왔지만, 해당 모델들을 제외하고 본다면,\n",
    "\n",
    "Median, Min-Max, Original, 4(depth), 3(leaf)\n",
    "\n",
    "Accuracy: 0.9999663684670748\n",
    "\n",
    "Precision: 0.9998618975279657\n",
    "\n",
    "Recall: 1.0\n",
    "\n",
    "F1: 0.9999309439955805\n",
    "\n",
    "가 가장 좋은 결과를 보여준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnRandomForestClassifier:\n",
    "  def __init__(self, n_estimators, max_depth, random_state):\n",
    "    self.n_estimators = n_estimators\n",
    "    self.max_depth = max_depth\n",
    "    self.random_state = random_state\n",
    "\n",
    "    self.classifier = ensemble.RandomForestClassifier(\n",
    "        n_estimators=self.n_estimators,\n",
    "        max_depth=self.max_depth,\n",
    "        random_state=self.random_state\n",
    "    )\n",
    "\n",
    "  def __call__(self, data):\n",
    "    return self.classifier.predict(data)\n",
    "\n",
    "  def train_model(self, train_data, train_label):\n",
    "      self.classifier.fit(train_data, train_label)\n",
    "\n",
    "  def test_model(self, test_data, test_label):\n",
    "\n",
    "    pred = self.classifier.predict(test_data)\n",
    "    accuracy = accuracy_score(test_label, pred)\n",
    "    precision = precision_score(test_label, pred)\n",
    "    recall = recall_score(test_label, pred)\n",
    "    f1_measure = f1_score(test_label, pred)\n",
    "\n",
    "    print('acc: {}/precision: {}/recall: {}/f1-measure: {}'.format(accuracy, precision, recall, f1_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean, min-max, original, 3, 100\n",
      "==========\n",
      "acc: 0.8613035582161835/precision: 1.0/recall: 0.4303867403314917/f1-measure: 0.6017767477790653\n",
      "\n",
      "mean, min-max, original, 3, 150\n",
      "==========\n",
      "acc: 0.8608327167552297/precision: 1.0/recall: 0.42845303867403317/f1-measure: 0.5998839682846645\n",
      "\n",
      "mean, min-max, original, 4, 100\n",
      "==========\n",
      "acc: 0.9096657025627228/precision: 1.0/recall: 0.6290055248618784/f1-measure: 0.7722570798711209\n",
      "\n",
      "mean, min-max, original, 4, 150\n",
      "==========\n",
      "acc: 0.9080177574493845/precision: 1.0/recall: 0.6222375690607734/f1-measure: 0.767134951042997\n",
      "\n",
      "mean, min-max, original, 5, 100\n",
      "==========\n",
      "acc: 0.9736328781865877/precision: 1.0/recall: 0.8917127071823204/f1-measure: 0.9427570093457944\n",
      "\n",
      "mean, min-max, original, 5, 150\n",
      "==========\n",
      "acc: 0.9557072711374185/precision: 1.0/recall: 0.8180939226519337/f1-measure: 0.8999468206335942\n",
      "\n",
      "mean, min-max, weight balance, 3, 100\n",
      "==========\n",
      "acc: 0.8613035582161835/precision: 1.0/recall: 0.4303867403314917/f1-measure: 0.6017767477790653\n",
      "\n",
      "mean, min-max, weight balance, 3, 150\n",
      "==========\n",
      "acc: 0.8608327167552297/precision: 1.0/recall: 0.42845303867403317/f1-measure: 0.5998839682846645\n",
      "\n",
      "mean, min-max, weight balance, 4, 100\n",
      "==========\n",
      "acc: 0.9096657025627228/precision: 1.0/recall: 0.6290055248618784/f1-measure: 0.7722570798711209\n",
      "\n",
      "mean, min-max, weight balance, 4, 150\n",
      "==========\n",
      "acc: 0.9080177574493845/precision: 1.0/recall: 0.6222375690607734/f1-measure: 0.767134951042997\n",
      "\n",
      "mean, min-max, weight balance, 5, 100\n",
      "==========\n",
      "acc: 0.9736328781865877/precision: 1.0/recall: 0.8917127071823204/f1-measure: 0.9427570093457944\n",
      "\n",
      "mean, min-max, weight balance, 5, 150\n",
      "==========\n",
      "acc: 0.9557072711374185/precision: 1.0/recall: 0.8180939226519337/f1-measure: 0.8999468206335942\n",
      "\n",
      "mean, min-max, undersample, 3, 100\n",
      "==========\n",
      "acc: 0.9787448711912289/precision: 0.9198221092757306/recall: 0.9998618784530386/f1-measure: 0.958173395102581\n",
      "\n",
      "mean, min-max, undersample, 3, 150\n",
      "==========\n",
      "acc: 0.9767942422815632/precision: 0.9130928355196771/recall: 0.9998618784530386/f1-measure: 0.9545094936708861\n",
      "\n",
      "mean, min-max, undersample, 4, 100\n",
      "==========\n",
      "acc: 0.998385686419587/precision: 0.9934138309549945/recall: 1.0/f1-measure: 0.9966960352422908\n",
      "\n",
      "mean, min-max, undersample, 4, 150\n",
      "==========\n",
      "acc: 0.9996636846707473/precision: 0.9986206896551724/recall: 1.0/f1-measure: 0.9993098688750862\n",
      "\n",
      "mean, min-max, undersample, 5, 100\n",
      "==========\n",
      "acc: 0.9993273693414946/precision: 0.9972451790633609/recall: 1.0/f1-measure: 0.9986206896551724\n",
      "\n",
      "mean, min-max, undersample, 5, 150\n",
      "==========\n",
      "acc: 0.9996636846707473/precision: 0.9986206896551724/recall: 1.0/f1-measure: 0.9993098688750862\n",
      "\n",
      "mean, min-max, oversample, 3, 100\n",
      "==========\n",
      "acc: 0.9792829757180332/precision: 0.9218033622007132/recall: 0.9997237569060774/f1-measure: 0.9591836734693877\n",
      "\n",
      "mean, min-max, oversample, 3, 150\n",
      "==========\n",
      "acc: 0.9793838703168091/precision: 0.9221556886227545/recall: 0.9997237569060774/f1-measure: 0.9593743786864604\n",
      "\n",
      "mean, min-max, oversample, 4, 100\n",
      "==========\n",
      "acc: 0.9985202125512881/precision: 0.9939593629873695/recall: 1.0/f1-measure: 0.9969705315340127\n",
      "\n",
      "mean, min-max, oversample, 4, 150\n",
      "==========\n",
      "acc: 0.9993946324073452/precision: 0.9975199779553596/recall: 1.0/f1-measure: 0.9987584494413022\n",
      "\n",
      "mean, min-max, oversample, 5, 100\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "mean, min-max, oversample, 5, 150\n",
      "==========\n",
      "acc: 0.9998654738682989/precision: 0.9994478188845941/recall: 1.0/f1-measure: 0.9997238331952499\n",
      "\n",
      "mean, standardization, original, 3, 100\n",
      "==========\n",
      "acc: 0.8613035582161835/precision: 1.0/recall: 0.4303867403314917/f1-measure: 0.6017767477790653\n",
      "\n",
      "mean, standardization, original, 3, 150\n",
      "==========\n",
      "acc: 0.8608327167552297/precision: 1.0/recall: 0.42845303867403317/f1-measure: 0.5998839682846645\n",
      "\n",
      "mean, standardization, original, 4, 100\n",
      "==========\n",
      "acc: 0.9096993340956481/precision: 1.0/recall: 0.6291436464088398/f1-measure: 0.7723611699872828\n",
      "\n",
      "mean, standardization, original, 4, 150\n",
      "==========\n",
      "acc: 0.9080177574493845/precision: 1.0/recall: 0.6222375690607734/f1-measure: 0.767134951042997\n",
      "\n",
      "mean, standardization, original, 5, 100\n",
      "==========\n",
      "acc: 0.9737001412524383/precision: 1.0/recall: 0.8919889502762431/f1-measure: 0.9429113739232005\n",
      "\n",
      "mean, standardization, original, 5, 150\n",
      "==========\n",
      "acc: 0.9557409026703437/precision: 1.0/recall: 0.8182320441988951/f1-measure: 0.900030385900942\n",
      "\n",
      "mean, standardization, weight balance, 3, 100\n",
      "==========\n",
      "acc: 0.8613035582161835/precision: 1.0/recall: 0.4303867403314917/f1-measure: 0.6017767477790653\n",
      "\n",
      "mean, standardization, weight balance, 3, 150\n",
      "==========\n",
      "acc: 0.8608327167552297/precision: 1.0/recall: 0.42845303867403317/f1-measure: 0.5998839682846645\n",
      "\n",
      "mean, standardization, weight balance, 4, 100\n",
      "==========\n",
      "acc: 0.9096993340956481/precision: 1.0/recall: 0.6291436464088398/f1-measure: 0.7723611699872828\n",
      "\n",
      "mean, standardization, weight balance, 4, 150\n",
      "==========\n",
      "acc: 0.9080177574493845/precision: 1.0/recall: 0.6222375690607734/f1-measure: 0.767134951042997\n",
      "\n",
      "mean, standardization, weight balance, 5, 100\n",
      "==========\n",
      "acc: 0.9737001412524383/precision: 1.0/recall: 0.8919889502762431/f1-measure: 0.9429113739232005\n",
      "\n",
      "mean, standardization, weight balance, 5, 150\n",
      "==========\n",
      "acc: 0.9557409026703437/precision: 1.0/recall: 0.8182320441988951/f1-measure: 0.900030385900942\n",
      "\n",
      "mean, standardization, undersample, 3, 100\n",
      "==========\n",
      "acc: 0.9708750924867156/precision: 0.8932625863770978/recall: 0.9998618784530386/f1-measure: 0.9435610010427529\n",
      "\n",
      "mean, standardization, undersample, 3, 150\n",
      "==========\n",
      "acc: 0.9753144548328513/precision: 0.9080531861515304/recall: 0.9998618784530386/f1-measure: 0.9517486195109124\n",
      "\n",
      "mean, standardization, undersample, 4, 100\n",
      "==========\n",
      "acc: 0.9981502656891101/precision: 0.9924605894448252/recall: 1.0/f1-measure: 0.9962160302717579\n",
      "\n",
      "mean, standardization, undersample, 4, 150\n",
      "==========\n",
      "acc: 0.9994618954731956/precision: 0.9977949283351709/recall: 1.0/f1-measure: 0.9988962472406181\n",
      "\n",
      "mean, standardization, undersample, 5, 100\n",
      "==========\n",
      "acc: 0.9998991054012242/precision: 0.9995858069860555/recall: 1.0/f1-measure: 0.9997928605951806\n",
      "\n",
      "mean, standardization, undersample, 5, 150\n",
      "==========\n",
      "acc: 0.9999327369341494/precision: 0.9997238331952499/recall: 1.0/f1-measure: 0.9998618975279657\n",
      "\n",
      "mean, standardization, oversample, 3, 100\n",
      "==========\n",
      "acc: 0.9644851012309141/precision: 0.8727996141789245/recall: 0.9998618784530386/f1-measure: 0.9320200849748937\n",
      "\n",
      "mean, standardization, oversample, 3, 150\n",
      "==========\n",
      "acc: 0.9665029932064303/precision: 0.8792517006802721/recall: 0.9997237569060774/f1-measure: 0.9356256463288521\n",
      "\n",
      "mean, standardization, oversample, 4, 100\n",
      "==========\n",
      "acc: 0.9969395305038004/precision: 0.9875869594871095/recall: 1.0/f1-measure: 0.9937547182760277\n",
      "\n",
      "mean, standardization, oversample, 4, 150\n",
      "==========\n",
      "acc: 0.998890159413466/precision: 0.9954626701498693/recall: 1.0/f1-measure: 0.9977261765313856\n",
      "\n",
      "mean, standardization, oversample, 5, 100\n",
      "==========\n",
      "acc: 0.9999327369341494/precision: 0.9997238331952499/recall: 1.0/f1-measure: 0.9998618975279657\n",
      "\n",
      "mean, standardization, oversample, 5, 150\n",
      "==========\n",
      "acc: 0.9999663684670748/precision: 0.9998618975279657/recall: 1.0/f1-measure: 0.9999309439955805\n",
      "\n",
      "mode, min-max, original, 3, 100\n",
      "==========\n",
      "acc: 0.9336449855384409/precision: 1.0/recall: 0.7274861878453038/f1-measure: 0.8422483409290797\n",
      "\n",
      "mode, min-max, original, 3, 150\n",
      "==========\n",
      "acc: 0.9222775274096994/precision: 1.0/recall: 0.6808011049723757/f1-measure: 0.8100912153833512\n",
      "\n",
      "mode, min-max, original, 4, 100\n",
      "==========\n",
      "acc: 0.9540929575570054/precision: 1.0/recall: 0.81146408839779/f1-measure: 0.8959207014868471\n",
      "\n",
      "mode, min-max, original, 4, 150\n",
      "==========\n",
      "acc: 0.9500235420730477/precision: 1.0/recall: 0.7947513812154696/f1-measure: 0.8856395259350469\n",
      "\n",
      "mode, min-max, original, 5, 100\n",
      "==========\n",
      "acc: 0.9860092823030874/precision: 0.9992683640620428/recall: 0.9432320441988951/f1-measure: 0.9704419496944721\n",
      "\n",
      "mode, min-max, original, 5, 150\n",
      "==========\n",
      "acc: 0.9821752875496065/precision: 0.9997021149836163/recall: 0.9270718232044199/f1-measure: 0.9620180593378242\n",
      "\n",
      "mode, min-max, weight balance, 3, 100\n",
      "==========\n",
      "acc: 0.9336449855384409/precision: 1.0/recall: 0.7274861878453038/f1-measure: 0.8422483409290797\n",
      "\n",
      "mode, min-max, weight balance, 3, 150\n",
      "==========\n",
      "acc: 0.9222775274096994/precision: 1.0/recall: 0.6808011049723757/f1-measure: 0.8100912153833512\n",
      "\n",
      "mode, min-max, weight balance, 4, 100\n",
      "==========\n",
      "acc: 0.9540929575570054/precision: 1.0/recall: 0.81146408839779/f1-measure: 0.8959207014868471\n",
      "\n",
      "mode, min-max, weight balance, 4, 150\n",
      "==========\n",
      "acc: 0.9500235420730477/precision: 1.0/recall: 0.7947513812154696/f1-measure: 0.8856395259350469\n",
      "\n",
      "mode, min-max, weight balance, 5, 100\n",
      "==========\n",
      "acc: 0.9860092823030874/precision: 0.9992683640620428/recall: 0.9432320441988951/f1-measure: 0.9704419496944721\n",
      "\n",
      "mode, min-max, weight balance, 5, 150\n",
      "==========\n",
      "acc: 0.9821752875496065/precision: 0.9997021149836163/recall: 0.9270718232044199/f1-measure: 0.9620180593378242\n",
      "\n",
      "mode, min-max, undersample, 3, 100\n",
      "==========\n",
      "acc: 0.987085491356696/precision: 0.9496327387198321/recall: 1.0/f1-measure: 0.9741657696447793\n",
      "\n",
      "mode, min-max, undersample, 3, 150\n",
      "==========\n",
      "acc: 0.9847985471177776/precision: 0.9412376495059802/recall: 1.0/f1-measure: 0.9697294401285829\n",
      "\n",
      "mode, min-max, undersample, 4, 100\n",
      "==========\n",
      "acc: 0.9888343310688101/precision: 0.9561542525092446/recall: 1.0/f1-measure: 0.9775857412908453\n",
      "\n",
      "mode, min-max, undersample, 4, 150\n",
      "==========\n",
      "acc: 0.9932400618820206/precision: 0.9729875016798817/recall: 1.0/f1-measure: 0.9863088345480553\n",
      "\n",
      "mode, min-max, undersample, 5, 100\n",
      "==========\n",
      "acc: 0.9953588484563126/precision: 0.9812957441040933/recall: 1.0/f1-measure: 0.9905595840744288\n",
      "\n",
      "mode, min-max, undersample, 5, 150\n",
      "==========\n",
      "acc: 0.9969731620367256/precision: 0.9877216916780355/recall: 1.0/f1-measure: 0.9938229238160604\n",
      "\n",
      "mode, min-max, oversample, 3, 100\n",
      "==========\n",
      "acc: 0.9810990784959979/precision: 0.928076923076923/recall: 0.9998618784530386/f1-measure: 0.9626329787234043\n",
      "\n",
      "mode, min-max, oversample, 3, 150\n",
      "==========\n",
      "acc: 0.9803928163045672/precision: 0.9255849635596471/recall: 0.9998618784530386/f1-measure: 0.9612907509461524\n",
      "\n",
      "mode, min-max, oversample, 4, 100\n",
      "==========\n",
      "acc: 0.9921638528284119/precision: 0.96882108925465/recall: 1.0/f1-measure: 0.9841636647862435\n",
      "\n",
      "mode, min-max, oversample, 4, 150\n",
      "==========\n",
      "acc: 0.994652586264882/precision: 0.97851060954183/recall: 1.0/f1-measure: 0.9891386023635494\n",
      "\n",
      "mode, min-max, oversample, 5, 100\n",
      "==========\n",
      "acc: 0.9950897961929105/precision: 0.9802328730029786/recall: 1.0/f1-measure: 0.9900177765622863\n",
      "\n",
      "mode, min-max, oversample, 5, 150\n",
      "==========\n",
      "acc: 0.9969395305038004/precision: 0.9875869594871095/recall: 1.0/f1-measure: 0.9937547182760277\n",
      "\n",
      "mode, standardization, original, 3, 100\n",
      "==========\n",
      "acc: 0.9336449855384409/precision: 1.0/recall: 0.7274861878453038/f1-measure: 0.8422483409290797\n",
      "\n",
      "mode, standardization, original, 3, 150\n",
      "==========\n",
      "acc: 0.9222775274096994/precision: 1.0/recall: 0.6808011049723757/f1-measure: 0.8100912153833512\n",
      "\n",
      "mode, standardization, original, 4, 100\n",
      "==========\n",
      "acc: 0.9540929575570054/precision: 1.0/recall: 0.81146408839779/f1-measure: 0.8959207014868471\n",
      "\n",
      "mode, standardization, original, 4, 150\n",
      "==========\n",
      "acc: 0.9500235420730477/precision: 1.0/recall: 0.7947513812154696/f1-measure: 0.8856395259350469\n",
      "\n",
      "mode, standardization, original, 5, 100\n",
      "==========\n",
      "acc: 0.9860092823030874/precision: 0.9992683640620428/recall: 0.9432320441988951/f1-measure: 0.9704419496944721\n",
      "\n",
      "mode, standardization, original, 5, 150\n",
      "==========\n",
      "acc: 0.9821752875496065/precision: 0.9997021149836163/recall: 0.9270718232044199/f1-measure: 0.9620180593378242\n",
      "\n",
      "mode, standardization, weight balance, 3, 100\n",
      "==========\n",
      "acc: 0.9336449855384409/precision: 1.0/recall: 0.7274861878453038/f1-measure: 0.8422483409290797\n",
      "\n",
      "mode, standardization, weight balance, 3, 150\n",
      "==========\n",
      "acc: 0.9222775274096994/precision: 1.0/recall: 0.6808011049723757/f1-measure: 0.8100912153833512\n",
      "\n",
      "mode, standardization, weight balance, 4, 100\n",
      "==========\n",
      "acc: 0.9540929575570054/precision: 1.0/recall: 0.81146408839779/f1-measure: 0.8959207014868471\n",
      "\n",
      "mode, standardization, weight balance, 4, 150\n",
      "==========\n",
      "acc: 0.9500235420730477/precision: 1.0/recall: 0.7947513812154696/f1-measure: 0.8856395259350469\n",
      "\n",
      "mode, standardization, weight balance, 5, 100\n",
      "==========\n",
      "acc: 0.9860092823030874/precision: 0.9992683640620428/recall: 0.9432320441988951/f1-measure: 0.9704419496944721\n",
      "\n",
      "mode, standardization, weight balance, 5, 150\n",
      "==========\n",
      "acc: 0.9821752875496065/precision: 0.9997021149836163/recall: 0.9270718232044199/f1-measure: 0.9620180593378242\n",
      "\n",
      "mode, standardization, undersample, 3, 100\n",
      "==========\n",
      "acc: 0.9812672361606242/precision: 0.9286722257857601/recall: 0.9998618784530386/f1-measure: 0.9629531094113735\n",
      "\n",
      "mode, standardization, undersample, 3, 150\n",
      "==========\n",
      "acc: 0.9833187596690657/precision: 0.9362225097024579/recall: 0.999585635359116/f1-measure: 0.9668670674682699\n",
      "\n",
      "mode, standardization, undersample, 4, 100\n",
      "==========\n",
      "acc: 0.9934754826124975/precision: 0.9739036857680925/recall: 1.0/f1-measure: 0.9867793376039253\n",
      "\n",
      "mode, standardization, undersample, 4, 150\n",
      "==========\n",
      "acc: 0.9945853231990314/precision: 0.9782461829482503/recall: 1.0/f1-measure: 0.9890034833686223\n",
      "\n",
      "mode, standardization, undersample, 5, 100\n",
      "==========\n",
      "acc: 0.995896952983117/precision: 0.9834284161912524/recall: 1.0/f1-measure: 0.9916449801397069\n",
      "\n",
      "mode, standardization, undersample, 5, 150\n",
      "==========\n",
      "acc: 0.9973094773659783/precision: 0.9890710382513661/recall: 1.0/f1-measure: 0.9945054945054945\n",
      "\n",
      "mode, standardization, oversample, 3, 100\n",
      "==========\n",
      "acc: 0.9840922849263469/precision: 0.9387887433536506/recall: 0.9998618784530386/f1-measure: 0.9683633201792522\n",
      "\n",
      "mode, standardization, oversample, 3, 150\n",
      "==========\n",
      "acc: 0.9841259164592722/precision: 0.9389105058365759/recall: 0.9998618784530386/f1-measure: 0.968428093645485\n",
      "\n",
      "mode, standardization, oversample, 4, 100\n",
      "==========\n",
      "acc: 0.9933745880137217/precision: 0.9735108242570929/recall: 1.0/f1-measure: 0.9865776384819787\n",
      "\n",
      "mode, standardization, oversample, 4, 150\n",
      "==========\n",
      "acc: 0.9948880069953588/precision: 0.9794372294372294/recall: 1.0/f1-measure: 0.9896118097320941\n",
      "\n",
      "mode, standardization, oversample, 5, 100\n",
      "==========\n",
      "acc: 0.9962668998452949/precision: 0.9849000136035914/recall: 1.0/f1-measure: 0.992392570762799\n",
      "\n",
      "mode, standardization, oversample, 5, 150\n",
      "==========\n",
      "acc: 0.9967041097733235/precision: 0.9866448623603161/recall: 1.0/f1-measure: 0.9932775415008918\n",
      "\n",
      "median, min-max, original, 3, 100\n",
      "==========\n",
      "acc: 0.8593529293065177/precision: 1.0/recall: 0.42237569060773483/f1-measure: 0.5939017284909691\n",
      "\n",
      "median, min-max, original, 3, 150\n",
      "==========\n",
      "acc: 0.8591511401089662/precision: 1.0/recall: 0.42154696132596686/f1-measure: 0.5930820054411193\n",
      "\n",
      "median, min-max, original, 4, 100\n",
      "==========\n",
      "acc: 0.8865944709759871/precision: 1.0/recall: 0.5342541436464089/f1-measure: 0.6964350018005041\n",
      "\n",
      "median, min-max, original, 4, 150\n",
      "==========\n",
      "acc: 0.8824577924261788/precision: 1.0/recall: 0.5172651933701657/f1-measure: 0.6818388711879836\n",
      "\n",
      "median, min-max, original, 5, 100\n",
      "==========\n",
      "acc: 0.9382861370821282/precision: 1.0/recall: 0.7465469613259669/f1-measure: 0.8548833531039937\n",
      "\n",
      "median, min-max, original, 5, 150\n",
      "==========\n",
      "acc: 0.9297437277191094/precision: 1.0/recall: 0.7114640883977901/f1-measure: 0.8314098942781051\n",
      "\n",
      "median, min-max, weight balance, 3, 100\n",
      "==========\n",
      "acc: 0.8593529293065177/precision: 1.0/recall: 0.42237569060773483/f1-measure: 0.5939017284909691\n",
      "\n",
      "median, min-max, weight balance, 3, 150\n",
      "==========\n",
      "acc: 0.8591511401089662/precision: 1.0/recall: 0.42154696132596686/f1-measure: 0.5930820054411193\n",
      "\n",
      "median, min-max, weight balance, 4, 100\n",
      "==========\n",
      "acc: 0.8865944709759871/precision: 1.0/recall: 0.5342541436464089/f1-measure: 0.6964350018005041\n",
      "\n",
      "median, min-max, weight balance, 4, 150\n",
      "==========\n",
      "acc: 0.8824577924261788/precision: 1.0/recall: 0.5172651933701657/f1-measure: 0.6818388711879836\n",
      "\n",
      "median, min-max, weight balance, 5, 100\n",
      "==========\n",
      "acc: 0.9382861370821282/precision: 1.0/recall: 0.7465469613259669/f1-measure: 0.8548833531039937\n",
      "\n",
      "median, min-max, weight balance, 5, 150\n",
      "==========\n",
      "acc: 0.9297437277191094/precision: 1.0/recall: 0.7114640883977901/f1-measure: 0.8314098942781051\n",
      "\n",
      "median, min-max, undersample, 3, 100\n",
      "==========\n",
      "acc: 0.9979148449586333/precision: 0.9916438356164383/recall: 0.9998618784530386/f1-measure: 0.995735900962861\n",
      "\n",
      "median, min-max, undersample, 3, 150\n",
      "==========\n",
      "acc: 0.9974103719647541/precision: 0.989476561432281/recall: 1.0/f1-measure: 0.9947104485814385\n",
      "\n",
      "median, min-max, undersample, 4, 100\n",
      "==========\n",
      "acc: 0.9986883702159144/precision: 0.9947780678851175/recall: 0.9998618784530386/f1-measure: 0.9973134945236619\n",
      "\n",
      "median, min-max, undersample, 4, 150\n",
      "==========\n",
      "acc: 0.9986211071500639/precision: 0.9943689053701414/recall: 1.0/f1-measure: 0.9971765029956614\n",
      "\n",
      "median, min-max, undersample, 5, 100\n",
      "==========\n",
      "acc: 0.9991592116768683/precision: 0.9965588437715073/recall: 1.0/f1-measure: 0.9982764563943468\n",
      "\n",
      "median, min-max, undersample, 5, 150\n",
      "==========\n",
      "acc: 0.9992937378085693/precision: 0.9971078363861727/recall: 1.0/f1-measure: 0.998551824012137\n",
      "\n",
      "median, min-max, oversample, 3, 100\n",
      "==========\n",
      "acc: 0.9980493710903343/precision: 0.9920526171553851/recall: 1.0/f1-measure: 0.9960104553583712\n",
      "\n",
      "median, min-max, oversample, 3, 150\n",
      "==========\n",
      "acc: 0.9970740566355014/precision: 0.9881261089122424/recall: 1.0/f1-measure: 0.994027596622503\n",
      "\n",
      "median, min-max, oversample, 4, 100\n",
      "==========\n",
      "acc: 0.9986883702159144/precision: 0.9946421211704904/recall: 1.0/f1-measure: 0.9973138645912253\n",
      "\n",
      "median, min-max, oversample, 4, 150\n",
      "==========\n",
      "acc: 0.9978139503598574/precision: 0.9911019849418207/recall: 1.0/f1-measure: 0.9955311103471983\n",
      "\n",
      "median, min-max, oversample, 5, 100\n",
      "==========\n",
      "acc: 0.9992264747427188/precision: 0.9968332644912571/recall: 1.0/f1-measure: 0.9984141212163\n",
      "\n",
      "median, min-max, oversample, 5, 150\n",
      "==========\n",
      "acc: 0.9991255801439429/precision: 0.9964216900633086/recall: 1.0/f1-measure: 0.9982076382186681\n",
      "\n",
      "median, standardization, original, 3, 100\n",
      "==========\n",
      "acc: 0.8593529293065177/precision: 1.0/recall: 0.42237569060773483/f1-measure: 0.5939017284909691\n",
      "\n",
      "median, standardization, original, 3, 150\n",
      "==========\n",
      "acc: 0.8591511401089662/precision: 1.0/recall: 0.42154696132596686/f1-measure: 0.5930820054411193\n",
      "\n",
      "median, standardization, original, 4, 100\n",
      "==========\n",
      "acc: 0.8865944709759871/precision: 1.0/recall: 0.5342541436464089/f1-measure: 0.6964350018005041\n",
      "\n",
      "median, standardization, original, 4, 150\n",
      "==========\n",
      "acc: 0.8824577924261788/precision: 1.0/recall: 0.5172651933701657/f1-measure: 0.6818388711879836\n",
      "\n",
      "median, standardization, original, 5, 100\n",
      "==========\n",
      "acc: 0.9382861370821282/precision: 1.0/recall: 0.7465469613259669/f1-measure: 0.8548833531039937\n",
      "\n",
      "median, standardization, original, 5, 150\n",
      "==========\n",
      "acc: 0.9297437277191094/precision: 1.0/recall: 0.7114640883977901/f1-measure: 0.8314098942781051\n",
      "\n",
      "median, standardization, weight balance, 3, 100\n",
      "==========\n",
      "acc: 0.8593529293065177/precision: 1.0/recall: 0.42237569060773483/f1-measure: 0.5939017284909691\n",
      "\n",
      "median, standardization, weight balance, 3, 150\n",
      "==========\n",
      "acc: 0.8591511401089662/precision: 1.0/recall: 0.42154696132596686/f1-measure: 0.5930820054411193\n",
      "\n",
      "median, standardization, weight balance, 4, 100\n",
      "==========\n",
      "acc: 0.8865944709759871/precision: 1.0/recall: 0.5342541436464089/f1-measure: 0.6964350018005041\n",
      "\n",
      "median, standardization, weight balance, 4, 150\n",
      "==========\n",
      "acc: 0.8824577924261788/precision: 1.0/recall: 0.5172651933701657/f1-measure: 0.6818388711879836\n",
      "\n",
      "median, standardization, weight balance, 5, 100\n",
      "==========\n",
      "acc: 0.9382861370821282/precision: 1.0/recall: 0.7465469613259669/f1-measure: 0.8548833531039937\n",
      "\n",
      "median, standardization, weight balance, 5, 150\n",
      "==========\n",
      "acc: 0.9297437277191094/precision: 1.0/recall: 0.7114640883977901/f1-measure: 0.8314098942781051\n",
      "\n",
      "median, standardization, undersample, 3, 100\n",
      "==========\n",
      "acc: 0.9971749512342772/precision: 0.9886642993717564/recall: 0.9998618784530386/f1-measure: 0.9942315615986815\n",
      "\n",
      "median, standardization, undersample, 3, 150\n",
      "==========\n",
      "acc: 0.9968386359050245/precision: 0.987315875613748/recall: 0.9998618784530386/f1-measure: 0.993549272577546\n",
      "\n",
      "median, standardization, undersample, 4, 100\n",
      "==========\n",
      "acc: 0.998251160287886/precision: 0.993139407244786/recall: 0.9997237569060774/f1-measure: 0.996420704845815\n",
      "\n",
      "median, standardization, undersample, 4, 150\n",
      "==========\n",
      "acc: 0.997645792695231/precision: 0.9904240766073872/recall: 1.0/f1-measure: 0.9951890034364261\n",
      "\n",
      "median, standardization, undersample, 5, 100\n",
      "==========\n",
      "acc: 0.9990246855451671/precision: 0.9960104553583712/recall: 1.0/f1-measure: 0.998001240609277\n",
      "\n",
      "median, standardization, undersample, 5, 150\n",
      "==========\n",
      "acc: 0.9986547386829892/precision: 0.9945054945054945/recall: 1.0/f1-measure: 0.9972451790633609\n",
      "\n",
      "median, standardization, oversample, 3, 100\n",
      "==========\n",
      "acc: 0.9978812134257079/precision: 0.9915080126010135/recall: 0.9998618784530386/f1-measure: 0.9956674231483392\n",
      "\n",
      "median, standardization, oversample, 3, 150\n",
      "==========\n",
      "acc: 0.997141319701352/precision: 0.988529291274068/recall: 0.9998618784530386/f1-measure: 0.9941632905307972\n",
      "\n",
      "median, standardization, oversample, 4, 100\n",
      "==========\n",
      "acc: 0.9984529494854375/precision: 0.9940934065934066/recall: 0.999585635359116/f1-measure: 0.996831955922865\n",
      "\n",
      "median, standardization, oversample, 4, 150\n",
      "==========\n",
      "acc: 0.997645792695231/precision: 0.9904240766073872/recall: 1.0/f1-measure: 0.9951890034364261\n",
      "\n",
      "median, standardization, oversample, 5, 100\n",
      "==========\n",
      "acc: 0.9978475818927827/precision: 0.9912376779846659/recall: 1.0/f1-measure: 0.9955995599559956\n",
      "\n",
      "median, standardization, oversample, 5, 150\n",
      "==========\n",
      "acc: 0.9979484764915585/precision: 0.9916449801397069/recall: 1.0/f1-measure: 0.9958049652706141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RF_hparams = hparams_dict.get('RandomForest')\n",
    "RF_max_depth_list = RF_hparams.get('max_depth')\n",
    "RF_n_estimators_list = RF_hparams.get('n_estimators')\n",
    "\n",
    "for missing_value in missing_value_list:\n",
    "  for scaling in scaling_list:\n",
    "    for imbalance in imbalance_dataset_list:\n",
    "      #데이터 불러오기\n",
    "      train_processed_array, train_label_array, test_processed_array, test_label_array = preprocess(missing_value, scaling, imbalance, test_data_ratio=0.2, random_state=42, verbose=False)\n",
    "\n",
    "      #Random Forest\n",
    "      for max_depth in RF_max_depth_list:\n",
    "        for n_estimators in RF_n_estimators_list:\n",
    "          \n",
    "            sklearn_rf_classifier = SklearnRandomForestClassifier(n_estimators, max_depth, random_state)\n",
    "            sklearn_rf_classifier.train_model(train_processed_array, train_label_array)\n",
    "\n",
    "            print(f'{missing_value}, {scaling}, {imbalance}, {max_depth}, {n_estimators}')\n",
    "            print(\"=\"*10)\n",
    "            sklearn_rf_classifier.test_model(test_processed_array, test_label_array)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1위 모델: mode, min-max, oversample, 5(max_depth), 150(n_estimators)\n",
    "\n",
    "Accuracy: 0.9999\n",
    "Precision: 0.9999\n",
    "Recall: 1.0\n",
    "F1-Measure: 0.9999\n",
    "Configuration: \n",
    "\n",
    "2위 모델: mode, min-max, undersample, 5(max_depth), 150(n_estimators)\n",
    "\n",
    "Accuracy: 0.9969\n",
    "Precision: 0.9877\n",
    "Recall: 1.0\n",
    "F1-Measure: 0.9938\n",
    "\n",
    "3위 모델: mode, standardization, undersample, 5(max_depth), 150(n_estimators)\n",
    "\n",
    "Accuracy: 0.9973\n",
    "Precision: 0.9891\n",
    "Recall: 1.0\n",
    "F1-Measure: 0.9945"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosted Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnGradientBoostingClassifier:\n",
    "  def __init__(self, n_estimators, max_depth, random_state):\n",
    "    self.n_estimators = n_estimators\n",
    "    self.max_depth = max_depth\n",
    "    self.random_state = random_state\n",
    "\n",
    "    self.classifier = ensemble.GradientBoostingClassifier(\n",
    "        n_estimators=self.n_estimators,\n",
    "        max_depth=self.max_depth,\n",
    "        random_state=self.random_state\n",
    "    )\n",
    "\n",
    "  def __call__(self, data):\n",
    "    return self.classifier.predict(data)\n",
    "\n",
    "  def train_model(self, train_data, train_label):\n",
    "      self.classifier.fit(train_data, train_label)\n",
    "\n",
    "  def test_model(self, test_data, test_label):\n",
    "    pred = self.classifier.predict(test_data)\n",
    "\n",
    "    accuracy = accuracy_score(test_label, pred)\n",
    "    recall = recall_score(test_label, pred)\n",
    "    precision = precision_score(test_label, pred)\n",
    "    f1 = f1_score(test_label, pred)\n",
    "\n",
    "    print('acc: {}'.format(accuracy))\n",
    "    print('recall: {}'.format(recall))\n",
    "    print('precision: {}'.format(precision))\n",
    "    print('f1: {}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean, min-max, original, 3, 100\n",
      "==========\n",
      "acc: 1.0\n",
      "recall: 1.0\n",
      "precision: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "mean, min-max, original, 3, 150\n",
      "==========\n",
      "acc: 1.0\n",
      "recall: 1.0\n",
      "precision: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "mean, min-max, original, 4, 100\n",
      "==========\n",
      "acc: 1.0\n",
      "recall: 1.0\n",
      "precision: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "mean, min-max, original, 4, 150\n",
      "==========\n",
      "acc: 1.0\n",
      "recall: 1.0\n",
      "precision: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "mean, min-max, original, 5, 100\n",
      "==========\n",
      "acc: 1.0\n",
      "recall: 1.0\n",
      "precision: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "mean, min-max, original, 5, 150\n",
      "==========\n",
      "acc: 1.0\n",
      "recall: 1.0\n",
      "precision: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "mean, min-max, weight balance, 3, 100\n",
      "==========\n",
      "acc: 1.0\n",
      "recall: 1.0\n",
      "precision: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "mean, min-max, weight balance, 3, 150\n",
      "==========\n",
      "acc: 1.0\n",
      "recall: 1.0\n",
      "precision: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "mean, min-max, weight balance, 4, 100\n",
      "==========\n",
      "acc: 1.0\n",
      "recall: 1.0\n",
      "precision: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "mean, min-max, weight balance, 4, 150\n",
      "==========\n",
      "acc: 1.0\n",
      "recall: 1.0\n",
      "precision: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "mean, min-max, weight balance, 5, 100\n",
      "==========\n",
      "acc: 1.0\n",
      "recall: 1.0\n",
      "precision: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "mean, min-max, weight balance, 5, 150\n",
      "==========\n",
      "acc: 1.0\n",
      "recall: 1.0\n",
      "precision: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "mean, min-max, undersample, 3, 100\n",
      "==========\n",
      "acc: 1.0\n",
      "recall: 1.0\n",
      "precision: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "mean, min-max, undersample, 3, 150\n",
      "==========\n",
      "acc: 1.0\n",
      "recall: 1.0\n",
      "precision: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "mean, min-max, undersample, 4, 100\n",
      "==========\n",
      "acc: 1.0\n",
      "recall: 1.0\n",
      "precision: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "mean, min-max, undersample, 4, 150\n",
      "==========\n",
      "acc: 1.0\n",
      "recall: 1.0\n",
      "precision: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "mean, min-max, undersample, 5, 100\n",
      "==========\n",
      "acc: 1.0\n",
      "recall: 1.0\n",
      "precision: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "mean, min-max, undersample, 5, 150\n",
      "==========\n",
      "acc: 1.0\n",
      "recall: 1.0\n",
      "precision: 1.0\n",
      "f1: 1.0\n",
      "\n",
      "mean, min-max, oversample, 3, 100\n",
      "==========\n",
      "acc: 1.0\n",
      "recall: 1.0\n",
      "precision: 1.0\n",
      "f1: 1.0\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_estimators \u001b[38;5;129;01min\u001b[39;00m RGBDT_n_estimators_list:\n\u001b[0;32m     15\u001b[0m     sklearn_gbdt_classifier\u001b[38;5;241m=\u001b[39m SklearnGradientBoostingClassifier(n_estimators, max_depth, random_state)\n\u001b[1;32m---> 16\u001b[0m     \u001b[43msklearn_gbdt_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_processed_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscaling\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimbalance\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_depth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_estimators\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[1;32mIn[76], line 17\u001b[0m, in \u001b[0;36mSklearnGradientBoostingClassifier.train_model\u001b[1;34m(self, train_data, train_label)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_data, train_label):\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\CHOI\\Documents\\MLDL_study\\venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\CHOI\\Documents\\MLDL_study\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:783\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    782\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 783\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\CHOI\\Documents\\MLDL_study\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:879\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    872\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(\n\u001b[0;32m    873\u001b[0m             y_true\u001b[38;5;241m=\u001b[39my_oob_masked,\n\u001b[0;32m    874\u001b[0m             raw_prediction\u001b[38;5;241m=\u001b[39mraw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    875\u001b[0m             sample_weight\u001b[38;5;241m=\u001b[39msample_weight_oob_masked,\n\u001b[0;32m    876\u001b[0m         )\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 879\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32mc:\\Users\\CHOI\\Documents\\MLDL_study\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:490\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    487\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    489\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csc \u001b[38;5;28;01mif\u001b[39;00m X_csc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 490\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_g_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    492\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    495\u001b[0m X_for_tree_update \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n",
      "File \u001b[1;32mc:\\Users\\CHOI\\Documents\\MLDL_study\\venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\CHOI\\Documents\\MLDL_study\\venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1377\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1350\u001b[0m \n\u001b[0;32m   1351\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1377\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\CHOI\\Documents\\MLDL_study\\venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RGBDT_hparams = hparams_dict.get('GBDT')\n",
    "RGBDT_max_depth_list = RGBDT_hparams.get('max_depth')\n",
    "RGBDT_n_estimators_list = RGBDT_hparams.get('n_estimators')\n",
    "\n",
    "for missing_value in missing_value_list:\n",
    "  for scaling in scaling_list:\n",
    "    for imbalance in imbalance_dataset_list:\n",
    "      #데이터 불러오기\n",
    "      train_processed_array, train_label_array, test_processed_array, test_label_array = preprocess(missing_value, scaling, imbalance, test_data_ratio=0.2, random_state=42, verbose=False)\n",
    "\n",
    "      #Random Forest\n",
    "      for max_depth in RGBDT_max_depth_list:\n",
    "        for n_estimators in RGBDT_n_estimators_list:\n",
    "          \n",
    "            sklearn_gbdt_classifier= SklearnGradientBoostingClassifier(n_estimators, max_depth, random_state)\n",
    "            sklearn_gbdt_classifier.train_model(train_processed_array, train_label_array)\n",
    "\n",
    "            print(f'{missing_value}, {scaling}, {imbalance}, {max_depth}, {n_estimators}')\n",
    "            print(\"=\"*10)\n",
    "            sklearn_gbdt_classifier.test_model(test_processed_array, test_label_array)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모등 결과가 동일하게 1이 나왔다..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
