{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model, model_selection\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "binomial_classification_data_path = './data/diabetes.csv'\n",
    "binomial_classification_feature_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi',  'pedigree', 'age',  'label']\n",
    "\n",
    "multinomial_classification_data_info = load_wine()\n",
    "multinomial_classification_feature_names = multinomial_classification_data_info.feature_names\n",
    "\n",
    "\n",
    "test_data_ratio = 0.3\n",
    "\n",
    "random_state = 0\n",
    "\n",
    "num_binomial_class = 2\n",
    "num_multinomial_class = 3\n",
    "\n",
    "learning_rate = 5e-3\n",
    "epochs = 200\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binomial classification train data: (537, 8)/binomial classification train label: (537,)\n",
      "binomial classification test data: (231, 8)/binomial classification test label: (231,)\n",
      "multionomial classification train data: (124, 13)/multionomial classification train label: (124,)\n",
      "multionomial classification test data: (54, 13)/multionomial classification test label: (54,)\n"
     ]
    }
   ],
   "source": [
    "class BinomialClassificationDataLoader:\n",
    "  def __init__(self, path, feature_names, test_data_ratio, random_state):\n",
    "    self.data_path = path\n",
    "    self.feature_names = feature_names\n",
    "    self.test_data_ratio = test_data_ratio\n",
    "    self.random_state = random_state\n",
    "\n",
    "    self.csv_infos = self.get_csv_infos()\n",
    "    self.csv_data, self.csv_label = self.get_csv_dataset()\n",
    "    self.train_data, self.train_label, self.test_data, self.test_label = self.get_split_data()\n",
    "    self.min_max_normalize_data()\n",
    "\n",
    "  def __call__(self, flag):\n",
    "    if flag == 'train':\n",
    "      return self.train_data, self.train_label\n",
    "    elif flag == 'test':\n",
    "      return self.test_data, self.test_label\n",
    "\n",
    "  def get_csv_infos(self):\n",
    "    df = pd.read_csv(self.data_path, header=None).drop([0], axis=0)\n",
    "    df.columns = self.feature_names\n",
    "\n",
    "    return df\n",
    "\n",
    "  def get_csv_dataset(self):\n",
    "    data, label = self.csv_infos[self.feature_names[:-1]], self.csv_infos[self.feature_names[-1]].astype(int)\n",
    "\n",
    "    return data.to_numpy().astype(np.float32), label.to_numpy().astype(np.float32)\n",
    "\n",
    "  def get_split_data(self):\n",
    "    train_data, test_data, train_label, test_label = model_selection.train_test_split(\n",
    "        self.csv_data, self.csv_label, test_size=self.test_data_ratio, random_state = self.random_state\n",
    "    )\n",
    "\n",
    "    return train_data, train_label, test_data, test_label\n",
    "\n",
    "  def min_max_normalize_data(self):\n",
    "    min_values = np.min(self.train_data, axis=0)\n",
    "    max_values = np.max(self.train_data, axis=0)\n",
    "\n",
    "    self.train_data = (self.train_data - min_values) / (max_values - min_values)\n",
    "    self.test_data = (self.test_data - min_values) / (max_values - min_values)\n",
    "\n",
    "\n",
    "class MultinomialClassificationDataLoader:\n",
    "  def __init__(self, data_info, feature_names, test_data_ratio, random_state):\n",
    "    self.data_info = data_info\n",
    "    self.feature_names = feature_names\n",
    "    self.test_data_ratio = test_data_ratio\n",
    "    self.random_state = random_state\n",
    "\n",
    "    self.data_infos = self.get_data_infos()\n",
    "    self.data, self.label = self.get_dataset()\n",
    "\n",
    "    self.train_data, self.train_label, self.test_data, self.test_label = self.get_split_data()\n",
    "    self.min_max_normalize_data()\n",
    "\n",
    "  def __call__(self, flag):\n",
    "    if flag == 'train':\n",
    "      return self.train_data, self.train_label\n",
    "    elif flag == 'test':\n",
    "      return self.test_data, self.test_label\n",
    "\n",
    "  def get_data_infos(self):\n",
    "    df = pd.DataFrame(self.data_info.data, columns=self.feature_names)\n",
    "    df['label'] = self.data_info.target\n",
    "\n",
    "    return df\n",
    "\n",
    "  def get_dataset(self):\n",
    "    data, label = self.data_infos.drop(columns=['label']), self.data_infos['label']\n",
    "\n",
    "    return data.to_numpy().astype(np.float32), label.to_numpy().astype(np.float32)\n",
    "\n",
    "  def get_split_data(self):\n",
    "    train_data, test_data, train_label, test_label = model_selection.train_test_split(\n",
    "        self.data, self.label, test_size=self.test_data_ratio, random_state = self.random_state\n",
    "    )\n",
    "    return train_data.astype(np.float32), train_label.astype(np.float32), test_data.astype(np.float32), test_label.astype(np.float32)\n",
    "\n",
    "  def min_max_normalize_data(self):\n",
    "    min_values = np.min(self.train_data, axis=0)\n",
    "    max_values = np.max(self.train_data, axis=0)\n",
    "\n",
    "    self.train_data = (self.train_data - min_values) / (max_values - min_values)\n",
    "    self.test_data = (self.test_data - min_values) / (max_values - min_values)\n",
    "\n",
    "\n",
    "binomial_classification_dataloader = BinomialClassificationDataLoader(binomial_classification_data_path, binomial_classification_feature_names, test_data_ratio, random_state)\n",
    "binomial_classification_train_data, binomial_classification_train_label = binomial_classification_dataloader('train')\n",
    "binomial_classification_test_data, binomial_classification_test_label = binomial_classification_dataloader('test')\n",
    "\n",
    "multinomial_classifcation_dataloader = MultinomialClassificationDataLoader(multinomial_classification_data_info, multinomial_classification_feature_names, test_data_ratio, random_state)\n",
    "multinomial_classifcation_train_data, multinomial_classifcation_train_label = multinomial_classifcation_dataloader('train')\n",
    "multinomial_classifcation_test_data, multinomial_classifcation_test_label = multinomial_classifcation_dataloader('test')\n",
    "\n",
    "print(f'binomial classification train data: {binomial_classification_train_data.shape}/binomial classification train label: {binomial_classification_train_label.shape}')\n",
    "print(f'binomial classification test data: {binomial_classification_test_data.shape}/binomial classification test label: {binomial_classification_test_label.shape}')\n",
    "\n",
    "print(f'multionomial classification train data: {multinomial_classifcation_train_data.shape}/multionomial classification train label: {multinomial_classifcation_train_label.shape}')\n",
    "print(f'multionomial classification test data: {multinomial_classifcation_test_data.shape}/multionomial classification test label: {multinomial_classifcation_test_label.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchBinomialLogisticRegression(nn.Module):\n",
    "  def __init__(self, data, num_class):\n",
    "    super(TorchBinomialLogisticRegression, self).__init__()\n",
    "    self.logistic_regressor = nn.Linear(data.shape[1], num_class)\n",
    "\n",
    "  def forward(self, data):\n",
    "    logit = self.logistic_regressor(data)\n",
    "\n",
    "    return logit\n",
    "\n",
    "  def get_params(self):\n",
    "    torch_weight, torch_bias = self.logistic_regressor.weight.detach().cpu().numpy(), self.logistic_regressor.bias.detach().cpu().numpy()\n",
    "\n",
    "    return torch_weight, torch_bias\n",
    "\n",
    "class TorchMultinomialLogisticRegression(nn.Module):\n",
    "  def __init__(self, data, num_class):\n",
    "    super(TorchMultinomialLogisticRegression, self).__init__()\n",
    "    self.logistic_regressor = nn.Linear(data.shape[1], num_class)\n",
    "\n",
    "  def forward(self, data):\n",
    "    logit = self.logistic_regressor(data)\n",
    "\n",
    "    return logit\n",
    "\n",
    "  def get_params(self):\n",
    "    torch_weight, torch_bias = self.logistic_regressor.weight.detach().cpu().numpy(), self.logistic_regressor.bias.detach().cpu().numpy()\n",
    "\n",
    "    return torch_weight, torch_bias\n",
    "\n",
    "class ScikitLearnLogisticRegression:\n",
    "  def __init__(self):\n",
    "    self.logistic_regressor = linear_model.LogisticRegression(penalty='l2')\n",
    "\n",
    "  def __call__(self, data):\n",
    "    pred = self.logistic_regressor.predict(data)\n",
    "\n",
    "    return pred\n",
    "\n",
    "  def get_params(self):\n",
    "    sklearn_weight, sklearn_bias = self.logistic_regressor.coef_, self.logistic_regressor.intercept_\n",
    "\n",
    "    return sklearn_weight, sklearn_bias\n",
    "\n",
    "\n",
    "binomial_sklearn_classifier = ScikitLearnLogisticRegression()\n",
    "binomial_torch_classifier = TorchBinomialLogisticRegression(binomial_classification_train_data, num_binomial_class).to(device)\n",
    "binomial_torch_model_optimizer = torch.optim.SGD(binomial_torch_classifier.parameters(), lr =learning_rate)\n",
    "\n",
    "multinomial_sklearn_classifier = ScikitLearnLogisticRegression()\n",
    "multinomial_torch_classifier = TorchMultinomialLogisticRegression(multinomial_classifcation_train_data, num_multinomial_class).to(device)\n",
    "multinomial_torch_model_optimizer = torch.optim.SGD(multinomial_torch_classifier.parameters(), lr =learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sklearn_model(data, label, model):\n",
    "  model.logistic_regressor.fit(data, label)\n",
    "\n",
    "\n",
    "def train_torch_model(data, label, model, criterion, optimizer, epochs, device):\n",
    "  model.train()\n",
    "\n",
    "  data, label = torch.tensor(data, dtype=torch.float32).to(device), torch.tensor(label, dtype=torch.long).to(device)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    result = model(data)\n",
    "\n",
    "    loss = criterion(result, label)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "train_sklearn_model(binomial_classification_train_data, binomial_classification_train_label, binomial_sklearn_classifier)\n",
    "train_torch_model(binomial_classification_train_data, binomial_classification_train_label, binomial_torch_classifier, criterion, binomial_torch_model_optimizer, epochs, device)\n",
    "\n",
    "train_sklearn_model(multinomial_classifcation_train_data, multinomial_classifcation_train_label, multinomial_sklearn_classifier)\n",
    "train_torch_model(multinomial_classifcation_train_data, multinomial_classifcation_train_label, multinomial_torch_classifier, criterion, multinomial_torch_model_optimizer, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn weight: [[ 1.0707948   4.33354734 -0.4743674   0.53145303 -0.07057994  2.95318117\n",
      "   1.16876891  1.31638619]]\n",
      "torch weight: [[-0.17271921  0.2857561   0.13505211 -0.13410577 -0.1989493   0.23358959\n",
      "   0.10040203  0.19158544]\n",
      " [ 0.13340668  0.2421252   0.21998887 -0.2636144   0.1104598   0.2599634\n",
      "  -0.03106291  0.2870178 ]]\n",
      "sklearn bias: [-5.32209008]\n",
      "torch bias: [ 0.31421492 -0.15382479]\n",
      "sklearn weight: [[ 1.33113482  0.06162319  0.483231   -1.06054689  0.06532169  0.77523869\n",
      "   1.51651302 -0.4735789   0.14388556  0.43597336  0.28142489  1.14143624\n",
      "   1.92525644]\n",
      " [-1.67642761 -0.87331901 -0.92009193  0.58843948 -0.24633828 -0.11866864\n",
      "   0.19239889  0.04369331  0.48606774 -1.74202569  0.88689904  0.51395912\n",
      "  -1.74774518]\n",
      " [ 0.34529279  0.81169581  0.43686093  0.47210741  0.1810166  -0.65657006\n",
      "  -1.70891191  0.42988559 -0.6299533   1.30605233 -1.16832393 -1.65539536\n",
      "  -0.17751125]]\n",
      "torch weight: [[ 0.32069722 -0.17195751 -0.02639375 -0.0076359   0.0171936   0.00912023\n",
      "   0.04907823 -0.27068573  0.22684084  0.1727523   0.26838192 -0.1438256\n",
      "  -0.04663027]\n",
      " [ 0.04886783 -0.2092947  -0.00680587  0.27442467 -0.06812632 -0.22220458\n",
      "  -0.09564273 -0.13673833 -0.12401081 -0.18242066  0.14673108  0.15234354\n",
      "  -0.25251746]\n",
      " [ 0.08297117 -0.02178794  0.00994933 -0.06510867 -0.21226463 -0.26944646\n",
      "   0.01818344  0.00932234 -0.10851371  0.2046602  -0.34548196 -0.09470689\n",
      "   0.15534407]]\n",
      "sklearn bias: [-2.86656185  2.33458166  0.53198019]\n",
      "torch bias: [-0.13266587  0.29267275  0.15316845]\n"
     ]
    }
   ],
   "source": [
    "def show_parameters(sklearn_model, torch_model):\n",
    "    sklearn_weight, sklearn_bias = sklearn_model.get_params()\n",
    "    torch_weight, torch_bias = torch_model.get_params()\n",
    "\n",
    "    print(f'sklearn weight: {sklearn_weight}\\ntorch weight: {torch_weight}')\n",
    "    print(f'sklearn bias: {sklearn_bias}\\ntorch bias: {torch_bias}')\n",
    "\n",
    "\n",
    "show_parameters(binomial_sklearn_classifier, binomial_torch_classifier)\n",
    "show_parameters(multinomial_sklearn_classifier, multinomial_torch_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-Learn Binomail Logstic Regression / Torch Binomial Logstic Regression\n",
      "acc: 0.7662337662337663\n",
      "recall: 0.4594594594594595\n",
      "precision: 0.7083333333333334\n",
      "f1 score: 0.5573770491803278\n",
      "acc: 0.6796536796536796\n",
      "recall: 0.0\n",
      "precision: 0.0\n",
      "f1 score: 0.0\n",
      "Scikit-Learn Multinomial Logstic Regression / Torch Multinomial Logstic Regression\n",
      "acc: 1.0\n",
      "acc: 0.8518518518518519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CHOI\\Documents\\MLDL_study\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def test_model(data, label, model, flag):\n",
    "    result = model(data)\n",
    "\n",
    "    accuracy = accuracy_score(label, result)\n",
    "    print(f'acc: {accuracy}')\n",
    "\n",
    "    if flag == 'binomial':\n",
    "        recall = recall_score(label, result)\n",
    "        precision = precision_score(label, result)\n",
    "        f1_measure = f1_score(label, result)\n",
    "\n",
    "        print(f'recall: {recall}')\n",
    "        print(f'precision: {precision}')\n",
    "        print(f'f1 score: {f1_measure}')\n",
    "\n",
    "def test_torch_model(data, label, model, device, flag):\n",
    "    model.eval()\n",
    "\n",
    "    data, label = torch.tensor(data, dtype=torch.float32).to(device), torch.tensor(label, dtype=torch.float32).detach().cpu().numpy()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        result = model(data)\n",
    "        _, result = torch.max(result, 1)\n",
    "        result = result.detach().cpu().numpy()\n",
    "        accuracy = accuracy_score(label, result)\n",
    "        print(f'acc: {accuracy}')\n",
    "\n",
    "        if flag == 'binomial':\n",
    "            recall = recall_score(label, result)\n",
    "            precision = precision_score(label, result)\n",
    "            f1_measure = f1_score(label, result)\n",
    "\n",
    "            print(f'recall: {recall}')\n",
    "            print(f'precision: {precision}')\n",
    "            print(f'f1 score: {f1_measure}')\n",
    "\n",
    "\n",
    "print('Scikit-Learn Binomail Logstic Regression / Torch Binomial Logstic Regression')\n",
    "test_model(binomial_classification_test_data, binomial_classification_test_label, binomial_sklearn_classifier, 'binomial')\n",
    "test_torch_model(binomial_classification_test_data, binomial_classification_test_label, binomial_torch_classifier, device, 'binomial')\n",
    "\n",
    "print('Scikit-Learn Multinomial Logstic Regression / Torch Multinomial Logstic Regression')\n",
    "test_model(multinomial_classifcation_test_data, multinomial_classifcation_test_label, multinomial_sklearn_classifier, 'multinomial')\n",
    "test_torch_model(multinomial_classifcation_test_data, multinomial_classifcation_test_label, multinomial_torch_classifier, device, 'multinomial')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
